# main.py
# ================================================
# ë†€ë©ì‰¬ë© ë°ì´í„° ê¸°ë°˜ ì œì£¼ ì—¬í–‰ ì½”ìŠ¤ ì¶”ì²œ API
# - attraction + food + stay ì¢…í•©
# - Day / ì½”ìŠ¤ ìˆœì„œë§Œ ì œê³µ (ì‹œê°„ ì •ë³´ ì—†ìŒ)
# - ìì—°ì–´/í‚¤ì›Œë“œ ì…ë ¥ ìë™ íŒŒì‹± (/recommend_text)
# - ì±—ë´‡ìš© /chat ì—”ë“œí¬ì¸íŠ¸ + ë£° ê¸°ë°˜ ì½”ìŠ¤ ì‘ë‹µ
# ================================================

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional, Tuple, Dict

import pandas as pd
import numpy as np
import re

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import linear_kernel

# ------------------------------------------------
# 0. FastAPI ê¸°ë³¸ ì„¤ì •
# ------------------------------------------------

app = FastAPI(title="Jeju Nolmeong-Swimeong Trip Recommender API")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # í•„ìš” ì‹œ í”„ë¡ íŠ¸ ë„ë©”ì¸ìœ¼ë¡œ ì œí•œ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
def root():
    return {"status": "FastAPI is running!"}

# ------------------------------------------------
# 1. CSV ë¡œë“œ & ê¸°ë³¸ ì „ì²˜ë¦¬
# ------------------------------------------------

# âœ… ë„¤ í™˜ê²½ì— ë§ê²Œë§Œ ë°”ê¿”ë‘” ê²½ë¡œ
CSV_PATH = "/Users/ijimin/jeju-app/backend/data/ë†€ë©ì‰¬ë© ë°ì´í„°.csv"

df = pd.read_csv(CSV_PATH)

# ì˜ˆìƒ ì»¬ëŸ¼: id, name, category, address, tags, thumbnailUrl,
#           descriptionShort, openingHours, phone, priceInfo, lat, lng
for col in ["name", "category", "address", "tags", "descriptionShort", "lat", "lng"]:
    if col not in df.columns:
        df[col] = np.nan if col in ["lat", "lng"] else ""

df["tags"] = df["tags"].fillna("")
df["descriptionShort"] = df["descriptionShort"].fillna("")
df["address"] = df["address"].fillna("")
df["category"] = df["category"].fillna("")

# ê²€ìƒ‰ìš© í…ìŠ¤íŠ¸: tags + descriptionShort
df["search_text"] = df["tags"].astype(str) + " " + df["descriptionShort"].astype(str)

# ------------------------------------------------
# 2. í–‰ì •êµ¬ì—­ & ì‚¬ë¶„ë©´ (ì œì£¼ ë™/ì„œ, ì„œê·€í¬ ë™/ì„œ)
# ------------------------------------------------

def extract_region_city(address: str) -> str:
    if not isinstance(address, str):
        return "ê¸°íƒ€"
    if "ì œì£¼ì‹œ" in address:
        return "ì œì£¼ì‹œ"
    if "ì„œê·€í¬ì‹œ" in address:
        return "ì„œê·€í¬ì‹œ"
    return "ê¸°íƒ€"

df["region_city"] = df["address"].apply(extract_region_city)

jeju_mask = (df["region_city"] == "ì œì£¼ì‹œ") & df["lng"].notna()
seogwipo_mask = (df["region_city"] == "ì„œê·€í¬ì‹œ") & df["lng"].notna()

JEJU_LNG_MID = df.loc[jeju_mask, "lng"].median() if jeju_mask.any() else 126.6
SEOGWIPO_LNG_MID = df.loc[seogwipo_mask, "lng"].median() if seogwipo_mask.any() else 126.6

# ì‹¤ì œ ì§€ëª… ê¸°ë°˜ ì‚¬ë¶„ë©´ ë§¤í•‘
NAME_TO_SUBREGION = {
    # ì œì£¼ì‹œ ì„œìª½
    "ì• ì›”": "ì œì£¼ ì„œ",
    "ì• ì›”ì": "ì œì£¼ ì„œ",
    "í•œë¦¼": "ì œì£¼ ì„œ",
    "í•œë¦¼ì": "ì œì£¼ ì„œ",
    "í˜‘ì¬": "ì œì£¼ ì„œ",
    "í•œê²½": "ì œì£¼ ì„œ",
    "í•œê²½ë©´": "ì œì£¼ ì„œ",
    "ê³ ì‚°": "ì œì£¼ ì„œ",
    "ì´í˜¸": "ì œì£¼ ì„œ",
    "ì´í˜¸ë™": "ì œì£¼ ì„œ",
    "ë„ë‘": "ì œì£¼ ì„œ",
    "ë„ë‘ë™": "ì œì£¼ ì„œ",
    # ì œì£¼ì‹œ ë™ìª½
    "ì¡°ì²œ": "ì œì£¼ ë™",
    "ì¡°ì²œì": "ì œì£¼ ë™",
    "í•¨ë•": "ì œì£¼ ë™",
    "í•¨ë•ë¦¬": "ì œì£¼ ë™",
    "êµ¬ì¢Œ": "ì œì£¼ ë™",
    "êµ¬ì¢Œì": "ì œì£¼ ë™",
    "ê¹€ë…•": "ì œì£¼ ë™",
    "ê¹€ë…•ë¦¬": "ì œì£¼ ë™",
    "ì„¸í™”": "ì œì£¼ ë™",
    "ì›”ì •": "ì œì£¼ ë™",
    "í‰ëŒ€": "ì œì£¼ ë™",
    "ìš°ë„": "ì œì£¼ ë™",
    # ì„œê·€í¬ ë™ìª½
    "ì„±ì‚°": "ì„œê·€í¬ ë™",
    "ì„±ì‚°ì": "ì„œê·€í¬ ë™",
    "í‘œì„ ": "ì„œê·€í¬ ë™",
    "í‘œì„ ë©´": "ì„œê·€í¬ ë™",
    "ë‚¨ì›": "ì„œê·€í¬ ë™",
    "ë‚¨ì›ì": "ì„œê·€í¬ ë™",
    # ì„œê·€í¬ ì„œìª½
    "ì¤‘ë¬¸": "ì„œê·€í¬ ì„œ",
    "ì¤‘ë¬¸ë™": "ì„œê·€í¬ ì„œ",
    "ì•ˆë•": "ì„œê·€í¬ ì„œ",
    "ì•ˆë•ë©´": "ì„œê·€í¬ ì„œ",
    "ëŒ€ì •": "ì„œê·€í¬ ì„œ",
    "ëŒ€ì •ì": "ì„œê·€í¬ ì„œ",
    "ëª¨ìŠ¬í¬": "ì„œê·€í¬ ì„œ",
    "í™”ìˆœ": "ì„œê·€í¬ ì„œ",
}

def classify_subregion(row) -> str:
    addr = row.get("address", "")
    city = row.get("region_city", "ê¸°íƒ€")
    lng = row.get("lng", np.nan)

    # 1) ì£¼ì†Œì— ì§€ëª…ì´ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
    if isinstance(addr, str):
        for name, sub in NAME_TO_SUBREGION.items():
            if name in addr:
                return sub

    # 2) lng ì—†ìœ¼ë©´ ë„ì‹œ ê¸°ì¤€ìœ¼ë¡œ ëŒ€ì¶© ë¶„ë¥˜
    if pd.isna(lng):
        if city == "ì œì£¼ì‹œ":
            return "ì œì£¼ ë™"
        elif city == "ì„œê·€í¬ì‹œ":
            return "ì„œê·€í¬ ë™"
        else:
            return "ê¸°íƒ€"

    # 3) lng ê¸°ì¤€ìœ¼ë¡œ ë™/ì„œ ë¶„í• 
    if city == "ì œì£¼ì‹œ":
        return "ì œì£¼ ë™" if lng >= JEJU_LNG_MID else "ì œì£¼ ì„œ"
    elif city == "ì„œê·€í¬ì‹œ":
        return "ì„œê·€í¬ ë™" if lng >= SEOGWIPO_LNG_MID else "ì„œê·€í¬ ì„œ"
    else:
        return "ê¸°íƒ€"

df["subregion"] = df.apply(classify_subregion, axis=1)

# ------------------------------------------------
# 3. í”„ë¡ íŠ¸ íƒœê·¸ ì •ì˜ & í™•ì¥ (TAGS / STAY_TAGS / FOOD_TAGS)
# ------------------------------------------------

BASE_TAGS = [
    {"key": "íœ´ì‹", "icon": "ğŸ§˜"},
    {"key": "ì¹œêµ¬ë“¤", "icon": "ğŸ‘«"},
    {"key": "í˜¼ì", "icon": "ğŸ§­"},
    {"key": "ë¬¸í™”", "icon": "ğŸ›ï¸"},
    {"key": "ìì—°", "icon": "ğŸï¸"},
    {"key": "ì‚¬ì§„", "icon": "ğŸ“·"},
    {"key": "ë°˜ë ¤ë™ë¬¼ ë™ë°˜", "icon": "ğŸ¶"},
    {"key": "ê°€ì¡±ì—¬í–‰", "icon": "ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦"},
    {"key": "ì•¡í‹°ë¹„í‹°", "icon": "ğŸ¯"},
    {"key": "ë”ë³´ê¸°", "icon": "â•"},
]

STAY_TAGS = [
    {"key": "ëŸ­ì…”ë¦¬", "icon": "ğŸ’"},
    {"key": "íœ´ì‹", "icon": "ğŸ›Œ"},
    {"key": "ê°€ì¡±ì—¬í–‰", "icon": "ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦"},
    {"key": "ì»¤í”Œ", "icon": "ğŸ’‘"},
    {"key": "ì‚¬ì§„", "icon": "ğŸ“·"},
    {"key": "ë°˜ë ¤ë™ë¬¼ ë™ë°˜", "icon": "ğŸ¶"},
    {"key": "ìì—°", "icon": "ğŸï¸"},
    {"key": "ì˜¤ì…˜ë·°", "icon": "ğŸŒŠ"},
    {"key": "í’€ë¹Œë¼", "icon": "ğŸŠ"},
    {"key": "ë”ë³´ê¸°", "icon": "â•"},
]

FOOD_TAGS = [
    {"key": "í‘ë¼ì§€", "icon": "ğŸ·"},
    {"key": "ê³ ê¸°êµ­ìˆ˜", "icon": "ğŸœ"},
    {"key": "í•´ì¥êµ­", "icon": "ğŸ¥£"},
    {"key": "ì œì£¼í–¥í† ìŒì‹", "icon": "ğŸ²"},
    {"key": "í•´ì‚°ë¬¼", "icon": "ğŸŸ"},
    {"key": "í•œì‹", "icon": "ğŸ±"},
    {"key": "ì¼ì‹", "icon": "ğŸ£"},
    {"key": "ì¤‘ì‹", "icon": "ğŸ¥¡"},
    {"key": "ì–‘ì‹", "icon": "ğŸ"},
    {"key": "ë”ë³´ê¸°", "icon": "â•"},
]

# ì¶”ê°€ íƒœê·¸(ë‚´ë¶€ìš©) - 'ë§›ì§‘' ê°™ì€ ê²ƒ
EXTRA_TAG_KEYS = [
    "ë§›ì§‘",
]

ALL_TAG_KEYS = {t["key"] for t in (BASE_TAGS + STAY_TAGS + FOOD_TAGS)} | set(EXTRA_TAG_KEYS)

TAG_TO_QUERY_EXPANSION = {
    "íœ´ì‹": "íœ´ì‹ íë§ ì¡°ìš©í•œ í•œì í•œ ì—¬ìœ  ì¹´í˜",
    "ì¹œêµ¬ë“¤": "ì¹œêµ¬ ë™í–‰ ë‹¨ì²´ ëª¨ì„",
    "í˜¼ì": "í˜¼ì ì†”ë¡œ í˜¼ìì—¬í–‰ ì¡°ìš©í•œ",
    "ë¬¸í™”": "ë¬¸í™” ì „ì‹œ ê³µì—° ì—­ì‚¬ ë°•ë¬¼ê´€ ê°¤ëŸ¬ë¦¬ ì²´í—˜",
    "ìì—°": "ìì—° ìˆ² ë°”ë‹¤ ì‚° ì˜¤ë¦„ ì „ë§ í’ê²½ í•´ë³€ ë“œë¼ì´ë¸Œ",
    "ì‚¬ì§„": "ì‚¬ì§„ í¬í†  í¬í† ìŠ¤íŒŸ ì¸ìƒìƒ· ë·° ì „ë§ ì•¼ê²½",
    "ë°˜ë ¤ë™ë¬¼ ë™ë°˜": "ë°˜ë ¤ë™ë¬¼ ë°˜ë ¤ê²¬ ì• ê²¬ ë™ë¬¼ ë™ë°˜",
    "ê°€ì¡±ì—¬í–‰": "ê°€ì¡± ê°€ì¡±ì—¬í–‰ ì•„ì´ ì–´ë¦°ì´ í‚¤ì¦ˆ",
    "ì•¡í‹°ë¹„í‹°": "ì•¡í‹°ë¹„í‹° ì²´í—˜ ë ˆì € ì„œí•‘ ìŠ¹ë§ˆ ì¹´ì•½",
    "ëŸ­ì…”ë¦¬": "ëŸ­ì…”ë¦¬ ê³ ê¸‰ í”„ë¦¬ë¯¸ì—„ ìŠ¤íŒŒ",
    "ì»¤í”Œ": "ì»¤í”Œ ì—°ì¸ ë¡œë§¨í‹± ë°ì´íŠ¸ ê°ì„±",
    "ì˜¤ì…˜ë·°": "ì˜¤ì…˜ë·° ë°”ë‹¤ë·° ë°”ë‹¤ì „ë§ í•´ë³€ í•´ì•ˆ",
    "í’€ë¹Œë¼": "í’€ë¹Œë¼ ìˆ˜ì˜ì¥ í”„ë¼ì´ë¹— ë…ì±„",
    "í‘ë¼ì§€": "í‘ë¼ì§€ ê³ ê¸° ì‚¼ê²¹ì‚´ êµ¬ì´",
    "ê³ ê¸°êµ­ìˆ˜": "ê³ ê¸°êµ­ìˆ˜ êµ­ìˆ˜ êµ­ë°¥",
    "í•´ì¥êµ­": "í•´ì¥êµ­ êµ­ë°¥",
    "ì œì£¼í–¥í† ìŒì‹": "í–¥í† ìŒì‹ ì œì£¼ìŒì‹ í† ì†ìŒì‹",
    "í•´ì‚°ë¬¼": "í•´ì‚°ë¬¼ íšŒ í•´ë¬¼ ìƒì„  ì¡°ê°œ",
    "í•œì‹": "í•œì‹ ë°±ë°˜ ì‹ë‹¹",
    "ì¼ì‹": "ì¼ì‹ ì´ˆë°¥ ìŠ¤ì‹œ",
    "ì¤‘ì‹": "ì¤‘ì‹ ì¤‘êµ­ì§‘ ì§œì¥ ì§¬ë½•",
    "ì–‘ì‹": "ì–‘ì‹ íŒŒìŠ¤íƒ€ í”¼ì ìŠ¤í…Œì´í¬",
    "ë§›ì§‘": "ë§›ì§‘ ìŒì‹ì  ì‹ë‹¹ ì¹´í˜ ë¡œì»¬ ë§›ì§‘",
}

def extract_tags_from_free_text(free_text: str) -> List[str]:
    if not free_text:
        return []
    tokens = re.split(r"[\s,]+", free_text.strip())
    extra_tags = set()
    for token in tokens:
        if not token:
            continue
        for tag in ALL_TAG_KEYS:
            if tag in token or token in tag:
                extra_tags.add(tag)
    return list(extra_tags)

def build_query_from_tags(selected_tags: List[str], free_text: str = "") -> Tuple[str, List[str]]:
    extra_tags = extract_tags_from_free_text(free_text)
    merged_tags = list(set(selected_tags) | set(extra_tags))

    tokens: List[str] = []
    for tag in merged_tags:
        t = tag.strip()
        if not t:
            continue
        tokens.append(t)
        if t in TAG_TO_QUERY_EXPANSION:
            tokens.append(TAG_TO_QUERY_EXPANSION[t])

    if free_text:
        tokens.append(free_text)

    query_text = " ".join(tokens)
    return query_text, merged_tags

# ------------------------------------------------
# 4. category â†’ place / food / stay ë§¤í•‘
# ------------------------------------------------

def map_category(cat: str) -> str:
    c = str(cat).lower()
    if c == "attraction":
        return "place"
    if c == "food":
        return "food"
    if c == "stay":
        return "stay"
    if any(k in c for k in ["food", "restaurant", "cafe", "ì‹ë‹¹", "ì¹´í˜", "ë§›ì§‘"]):
        return "food"
    if any(k in c for k in ["stay", "hotel", "ìˆ™ì†Œ", "íœì…˜", "ë¦¬ì¡°íŠ¸", "ê²ŒìŠ¤íŠ¸í•˜ìš°ìŠ¤"]):
        return "stay"
    return "place"

df["category_mapped"] = df["category"].map(map_category)

# âœ… ì‚¬ëŒ ì½ê¸°ìš© ì¹´í…Œê³ ë¦¬ ë¼ë²¨ (ì´ ë¶€ë¶„ì´ ìƒˆë¡œ ë“¤ì–´ê°„ ë¶€ë¶„)
CATEGORY_LABEL = {
    "place": "ê´€ê´‘",
    "food": "ì‹ì‚¬",
    "stay": "ìˆ™ì†Œ",
}

# ------------------------------------------------
# 5. TF-IDF í•™ìŠµ
# ------------------------------------------------

vectorizer = TfidfVectorizer(token_pattern=r"(?u)\b\w+\b")
tfidf_matrix = vectorizer.fit_transform(df["search_text"])

# ------------------------------------------------
# 6. í—¬í¼: ì •ë ¬ / í›„ë³´ ì„ íƒ
# ------------------------------------------------

def sort_by_subregion_then_similarity(sub_df: pd.DataFrame) -> pd.DataFrame:
    sub_df = sub_df.copy()
    sub_df["subregion"] = sub_df["subregion"].fillna("ê¸°íƒ€")
    order_map = {"ì œì£¼ ë™": 0, "ì œì£¼ ì„œ": 1, "ì„œê·€í¬ ë™": 2, "ì„œê·€í¬ ì„œ": 3, "ê¸°íƒ€": 4}
    sub_df["subrank"] = sub_df["subregion"].map(lambda x: order_map.get(x, 99))
    sub_df = sub_df.sort_values(
        by=["subrank", "similarity"],
        ascending=[True, False]
    ).reset_index(drop=True)
    return sub_df.drop(columns=["subrank"])

def get_best_candidate(
    df_cat: pd.DataFrame,
    used_indices: set,
    preferred_subregion: Optional[str] = None,
) -> Optional[pd.Series]:
    if df_cat.empty:
        return None
    if preferred_subregion:
        sub = df_cat[
            (df_cat["subregion"] == preferred_subregion) &
            (~df_cat["orig_idx"].isin(used_indices))
        ]
        if not sub.empty:
            return sub.iloc[0]
    rest = df_cat[~df_cat["orig_idx"].isin(used_indices)]
    if rest.empty:
        return None
    return rest.iloc[0]

# ------------------------------------------------
# 7. ë©”ì¸ ì¶”ì²œ ë¡œì§ (ì‹œê°„ X, Day/ìˆœì„œë§Œ)
# ------------------------------------------------

def recommend_itinerary_no_time(
    selected_tags: List[str],
    region_filter_address: Optional[str] = None,
    region_filter_subregions: Optional[List[str]] = None,
    days: int = 1,
    max_places_per_day: int = 3,
    free_text: str = "",
) -> pd.DataFrame:
    """
    - íƒœê·¸ + freeText ê¸°ë°˜ TF-IDF ìœ ì‚¬ë„
    - place / food / stayë¥¼ ì¢…í•©í•´ì„œ Dayë³„ ì½”ìŠ¤ êµ¬ì„±
      * place ì—¬ëŸ¬ ê°œ (max_places_per_day)
      * ì²« place ë’¤ì— food 1ê°œ ë¼ì›Œ ë„£ê¸°
      * ë§ˆì§€ë§‰ì— stay 1ê°œ ë¶™ì´ê¸°
    - region_filter_address: ì£¼ì†Œ ë¬¸ìì—´ í•„í„° (ì• ì›”, ì„±ì‚°, ì¤‘ë¬¸ ë“±)
    - region_filter_subregions: ["ì œì£¼ ì„œ", "ì„œê·€í¬ ì„œ"] ë“± ì‚¬ë¶„ë©´ í•„í„°
    """

    query_text, merged_tags = build_query_from_tags(selected_tags, free_text=free_text)
    if not query_text.strip():
        return pd.DataFrame()

    candidate_df = df.copy()
    candidate_df["orig_idx"] = candidate_df.index

    # 1) ì£¼ì†Œ ê¸°ë°˜ ì§€ì—­ í•„í„°
    if region_filter_address and region_filter_address.strip():
        mask_region = candidate_df["address"].str.contains(region_filter_address.strip(), na=False)
        candidate_df = candidate_df[mask_region]

    # 2) ì‚¬ë¶„ë©´ ê¸°ë°˜ í•„í„° (ì„œìª½/ë™ìª½ ë“±)
    if region_filter_subregions:
        candidate_df = candidate_df[candidate_df["subregion"].isin(region_filter_subregions)]

    # ë§Œì•½ í•„í„° ë•Œë¬¸ì— ë¹„ì–´ë²„ë¦¬ë©´ ì „ì²´ë¡œ fallback
    if len(candidate_df) == 0:
        candidate_df = df.copy()
        candidate_df["orig_idx"] = candidate_df.index

    idx_list = candidate_df["orig_idx"].tolist()
    candidate_tfidf = tfidf_matrix[idx_list]
    query_vec = vectorizer.transform([query_text])
    cosine_sim = linear_kernel(query_vec, candidate_tfidf).flatten()
    candidate_df["similarity"] = cosine_sim

    place_df = sort_by_subregion_then_similarity(
        candidate_df[candidate_df["category_mapped"] == "place"]
    ).copy()
    food_df = sort_by_subregion_then_similarity(
        candidate_df[candidate_df["category_mapped"] == "food"]
    ).copy()
    stay_df = sort_by_subregion_then_similarity(
        candidate_df[candidate_df["category_mapped"] == "stay"]
    ).copy()

    if place_df.empty and food_df.empty and stay_df.empty:
        return pd.DataFrame()

    total_place_needed = days * max_places_per_day
    place_df = place_df.head(total_place_needed).reset_index(drop=True)

    used_indices: set = set()
    results = []

    for day in range(1, days + 1):
        start_idx = (day - 1) * max_places_per_day
        end_idx = day * max_places_per_day
        day_places = place_df.iloc[start_idx:end_idx]
        day_places = day_places[~day_places["orig_idx"].isin(used_indices)].reset_index(drop=True)

        if day_places.empty:
            continue

        dominant_sub = (
            day_places["subregion"].value_counts().idxmax()
            if not day_places["subregion"].empty
            else None
        )

        day_food_candidate = get_best_candidate(food_df, used_indices, preferred_subregion=dominant_sub)
        last_place_sub = day_places.iloc[-1]["subregion"]
        day_stay_candidate = get_best_candidate(stay_df, used_indices, preferred_subregion=last_place_sub)

        day_items = []
        for i, (_, prow) in enumerate(day_places.iterrows()):
            day_items.append(("place", prow))
            # ì²« ë²ˆì§¸ ê´€ê´‘ì§€ ë’¤ì— ë§›ì§‘ 1ê°œ ë¼ì›Œ ë„£ê¸°
            if i == 0 and day_food_candidate is not None:
                day_items.append(("food", day_food_candidate))

        if day_stay_candidate is not None:
            day_items.append(("stay", day_stay_candidate))

        order_in_day = 0
        for cat, row in day_items:
            if pd.isna(row.get("orig_idx", np.nan)):
                continue
            if row["orig_idx"] in used_indices:
                continue

            used_indices.add(row["orig_idx"])
            order_in_day += 1

            results.append({
                "day": day,
                "order_in_day": order_in_day,
                "name": row.get("name", ""),
                "category": cat,  # place / food / stay (ë‚´ë¶€ ì½”ë“œ)
                "address": row.get("address", ""),
                "region_city": row.get("region_city", ""),
                "subregion": row.get("subregion", ""),
                "tags": row.get("tags", ""),
                "descriptionShort": row.get("descriptionShort", ""),
                "similarity": float(row["similarity"]),
                "lat": row.get("lat"),
                "lng": row.get("lng"),
            })

    if not results:
        return pd.DataFrame()

    return pd.DataFrame(results)

# ------------------------------------------------
# 8. ìì—°ì–´/í‚¤ì›Œë“œ íŒŒì„œ (ê³ ë„í™” ë²„ì „ - /recommend_textìš©)
# ------------------------------------------------

# í•œê¸€ ìˆ«ì ê°„ë‹¨ ë§¤í•‘
KOREAN_NUM_MAP = {
    "í•œ": 1, "í•˜ë‚˜": 1, "í•˜ë£¨": 1,
    "ë‘": 2, "ë‘˜": 2, "ì´í‹€": 2,
    "ì„¸": 3, "ì…‹": 3, "ì‚¬í˜": 3,
    "ë„¤": 4, "ë„·": 4,
}

def parse_days(text: str) -> int:
    # 3ë°•4ì¼, 2ë°• 3ì¼
    m = re.search(r"(\d+)\s*ë°•\s*(\d+)\s*ì¼", text)
    if m:
        return max(int(m.group(2)), 1)

    # 2ë°• / 3ë°•
    m = re.search(r"(\d+)\s*ë°•", text)
    if m:
        return max(int(m.group(1)) + 1, 1)

    # 3ì¼ / 4ì¼
    m = re.search(r"(\d+)\s*ì¼", text)
    if m:
        return max(int(m.group(1)), 1)

    # í•œê¸€ í•˜ë£¨/ì´í‹€/ì‚¬í˜
    for k, v in KOREAN_NUM_MAP.items():
        if k in text and "ì¼" in text:
            return v

    # ë‹¹ì¼ì¹˜ê¸°
    if "ë‹¹ì¼" in text or "ë‹¹ì¼ì¹˜ê¸°" in text or "í•˜ë£¨" in text:
        return 1

    return 1

def parse_region(text: str):
    """
    return (region_address_keyword, region_subregions)
    """
    # ìš°ì„ ìˆœìœ„: êµ¬ì²´ ì§€ì—­ â†’ ì„œìª½/ë™ìª½
    addr_keywords = {
        "ì œì£¼ì‹œ": "ì œì£¼ì‹œ",
        "ì„œê·€í¬": "ì„œê·€í¬ì‹œ",
        "ì• ì›”": "ì• ì›”",
        "í˜‘ì¬": "í˜‘ì¬",
        "í•œë¦¼": "í•œë¦¼",
        "ì„±ì‚°": "ì„±ì‚°",
        "í‘œì„ ": "í‘œì„ ",
        "ë‚¨ì›": "ë‚¨ì›",
        "ì¤‘ë¬¸": "ì¤‘ë¬¸",
        "í•œê²½": "í•œê²½",
        "ëŒ€ì •": "ëŒ€ì •",
        "ì¡°ì²œ": "ì¡°ì²œ",
        "í•¨ë•": "í•¨ë•",
        "êµ¬ì¢Œ": "êµ¬ì¢Œ",
        "ê¹€ë…•": "ê¹€ë…•",
        "ì„¸í™”": "ì„¸í™”",
        "ì›”ì •": "ì›”ì •",
        "í‰ëŒ€": "í‰ëŒ€",
        "ìš°ë„": "ìš°ë„",
    }

    for k, v in addr_keywords.items():
        if k in text:
            return v, None

    # ì„œìª½/ì„œë¶€/ì„œìª½ì½”ìŠ¤ â†’ ì œì£¼ ì„œ + ì„œê·€í¬ ì„œ
    if "ì„œìª½" in text or "ì„œë¶€" in text:
        return None, ["ì œì£¼ ì„œ", "ì„œê·€í¬ ì„œ"]

    # ë™ìª½/ë™ë¶€ â†’ ì œì£¼ ë™ + ì„œê·€í¬ ë™
    if "ë™ìª½" in text or "ë™ë¶€" in text:
        return None, ["ì œì£¼ ë™", "ì„œê·€í¬ ë™"]

    # ê·¸ëƒ¥ "ì„œê·€í¬", "ì œì£¼ì‹œ"ëŠ” address keywordë¡œ
    if "ì„œê·€í¬" in text:
        return "ì„œê·€í¬ì‹œ", None
    if "ì œì£¼ì‹œ" in text:
        return "ì œì£¼ì‹œ", None

    return None, None

def parse_tags_from_text(text: str) -> List[str]:
    tag_map = {
        # ê°ì„±/ê´€ê³„
        "ì»¤í”Œ": "ì»¤í”Œ",
        "ë°ì´íŠ¸": "ì»¤í”Œ",
        "ì—°ì¸": "ì»¤í”Œ",
        "í—ˆë‹ˆë¬¸": "ì»¤í”Œ",

        "ê°€ì¡±": "ê°€ì¡±ì—¬í–‰",
        "ì•„ì´": "ê°€ì¡±ì—¬í–‰",
        "ì–´ë¦°ì´": "ê°€ì¡±ì—¬í–‰",
        "í‚¤ì¦ˆ": "ê°€ì¡±ì—¬í–‰",

        # ë¶„ìœ„ê¸°
        "ìì—°": "ìì—°",
        "ë°”ë‹¤": "ìì—°",
        "í•´ë³€": "ìì—°",
        "ì˜¤ë¦„": "ìì—°",
        "ë“œë¼ì´ë¸Œ": "ìì—°",
        "í’ê²½": "ìì—°",

        "íë§": "íœ´ì‹",
        "ì¡°ìš©": "íœ´ì‹",
        "í•œì ": "íœ´ì‹",
        "íœ´ì‹": "íœ´ì‹",
        "ì—¬ìœ ": "íœ´ì‹",

        "ì‚¬ì§„": "ì‚¬ì§„",
        "ì¸ìƒìƒ·": "ì‚¬ì§„",
        "ê°ì„±": "ì‚¬ì§„",

        "ì•¡í‹°ë¹„í‹°": "ì•¡í‹°ë¹„í‹°",
        "ì²´í—˜": "ì•¡í‹°ë¹„í‹°",
        "ë ˆì €": "ì•¡í‹°ë¹„í‹°",
        "ì„œí•‘": "ì•¡í‹°ë¹„í‹°",

        "ë°˜ë ¤": "ë°˜ë ¤ë™ë¬¼ ë™ë°˜",
        "ì• ê²¬": "ë°˜ë ¤ë™ë¬¼ ë™ë°˜",

        "ëŸ­ì…”ë¦¬": "ëŸ­ì…”ë¦¬",
        "ê³ ê¸‰": "ëŸ­ì…”ë¦¬",

        "ì˜¤ì…˜ë·°": "ì˜¤ì…˜ë·°",
        "ë°”ë‹¤ë·°": "ì˜¤ì…˜ë·°",

        "í’€ë¹Œë¼": "í’€ë¹Œë¼",

        # ìŒì‹ ê´€ë ¨
        "ë§›ì§‘": "ë§›ì§‘",
        "ë¨¹ë°©": "ë§›ì§‘",
        "ì‹ë„ë½": "ë§›ì§‘",
        "ì¹´í˜": "ë§›ì§‘",
        "í‘ë¼ì§€": "í‘ë¼ì§€",
        "ê³ ê¸°êµ­ìˆ˜": "ê³ ê¸°êµ­ìˆ˜",
        "í•´ì‚°ë¬¼": "í•´ì‚°ë¬¼",
        "íšŒ": "í•´ì‚°ë¬¼",
    }

    tags = []
    for k, mapped_tag in tag_map.items():
        if k in text:
            tags.append(mapped_tag)

    tags = list(set(tags))

    # ì•„ë¬´ íƒœê·¸ë„ ì•ˆ ì¡íˆë©´ ê¸°ë³¸ì ìœ¼ë¡œ 'ìì—°'ì„ ë„£ì–´ì¤˜ì„œ ë„ˆë¬´ ëœë¤í•´ì§€ì§€ ì•Šê²Œ
    if not tags:
        tags = ["ìì—°"]

    return tags

def parse_user_query_advanced(query: str):
    """
    ìì—°ì–´/ì§§ì€ í‚¤ì›Œë“œ â†’ days, tags, region(Address/Subregion), freeText
    ( /recommend_text ì—ì„œ ì‚¬ìš© )
    """
    original = query
    text = query.strip()

    # ì†Œë¬¸ì ë³€í™˜(ì˜ë¬¸ìš©), í•œê¸€ì—” ì˜í–¥ ê±°ì˜ ì—†ìŒ
    low = text.lower()

    days = parse_days(low)
    addr_kw, subregions = parse_region(text)
    tags = parse_tags_from_text(text)

    # freeTextëŠ” TF-IDFìš©ìœ¼ë¡œ ë¬¸ì¥ ì „ì²´ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    freeText = original

    return {
        "original": original,
        "days": days,
        "tags": tags,
        "region_address": addr_kw,
        "region_subregions": subregions,
        "freeText": freeText,
    }

# ------------------------------------------------
# 8-1. ì±—ë´‡ìš© ê°„ë‹¨ íŒŒì„œ (ë„¤ê°€ ì“°ë˜ parse_chat_message ê·¸ëŒ€ë¡œ)
# ------------------------------------------------

KEYWORD_TO_TAG = {
    # ë™í–‰ / ë¶„ìœ„ê¸°
    "ì»¤í”Œ": "ì»¤í”Œ",
    "ë°ì´íŠ¸": "ì»¤í”Œ",
    "ì‹ í˜¼": "ì»¤í”Œ",
    "í—ˆë‹ˆë¬¸": "ì»¤í”Œ",
    "ë¶€ë¶€": "ì»¤í”Œ",

    "ê°€ì¡±": "ê°€ì¡±ì—¬í–‰",
    "ì•„ì´": "ê°€ì¡±ì—¬í–‰",
    "í‚¤ì¦ˆ": "ê°€ì¡±ì—¬í–‰",
    "ì• ë“¤": "ê°€ì¡±ì—¬í–‰",

    "í˜¼ì": "í˜¼ì",
    "í˜¼í–‰": "í˜¼ì",

    # ë¶„ìœ„ê¸° / í™œë™
    "íë§": "íœ´ì‹",
    "ì‰¬ê³ ": "íœ´ì‹",
    "íœ´ì‹": "íœ´ì‹",
    "ì¹´í˜": "íœ´ì‹",
    "ì¹´ê³µ": "íœ´ì‹",

    "ë°”ë‹¤": "ìì—°",
    "í•´ë³€": "ìì—°",
    "í•´ìˆ˜ìš•ì¥": "ìì—°",
    "ì˜¤ì…˜ë·°": "ì˜¤ì…˜ë·°",
    "ë·°ë§›ì§‘": "ì‚¬ì§„",
    "ì‚¬ì§„": "ì‚¬ì§„",
    "í¬í† ": "ì‚¬ì§„",
    "ì¸ìƒìƒ·": "ì‚¬ì§„",

    "ì˜¤ë¦„": "ìì—°",
    "ì‚°": "ìì—°",
    "ìˆ²": "ìì—°",

    # ìŒì‹ ì·¨í–¥
    "í‘ë¼ì§€": "í‘ë¼ì§€",
    "ê³ ê¸°êµ­ìˆ˜": "ê³ ê¸°êµ­ìˆ˜",
    "í•´ì‚°ë¬¼": "í•´ì‚°ë¬¼",
    "íšŒ": "í•´ì‚°ë¬¼",
    "í–¥í† ìŒì‹": "ì œì£¼í–¥í† ìŒì‹",
}

AREA_KEYWORDS = {
    # ì œì£¼ì‹œ ì„œìª½ (ì• ì›”/í•œë¦¼/í˜‘ì¬/í•œê²½/ì´í˜¸/ë„ë‘)
    "ì œì£¼ ì„œìª½": {
        "pattern": "ì• ì›”|í•œë¦¼|í˜‘ì¬|í•œê²½|ì´í˜¸|ë„ë‘",
        "label": "ì œì£¼ì‹œ ì„œìª½(ì• ì›”Â·í•œë¦¼Â·í˜‘ì¬ ì¼ëŒ€)",
    },
    "ì• ì›”": {
        "pattern": "ì• ì›”",
        "label": "ì• ì›” ì¼ëŒ€",
    },
    "í•œë¦¼": {
        "pattern": "í•œë¦¼|í˜‘ì¬",
        "label": "í•œë¦¼Â·í˜‘ì¬ ì¼ëŒ€",
    },

    # ì œì£¼ì‹œ ë™ìª½
    "ì œì£¼ ë™ìª½": {
        "pattern": "ì¡°ì²œ|í•¨ë•|êµ¬ì¢Œ|ê¹€ë…•|ì„¸í™”|ì›”ì •|í‰ëŒ€|ìš°ë„",
        "label": "ì œì£¼ì‹œ ë™ìª½(í•¨ë•Â·êµ¬ì¢Œ ì¼ëŒ€)",
    },

    # ì„œê·€í¬ ì„œìª½ (ì¤‘ë¬¸/ì•ˆë•/ëŒ€ì •/ëª¨ìŠ¬í¬/í™”ìˆœ)
    "ì¤‘ë¬¸": {
        "pattern": "ì¤‘ë¬¸|ì•ˆë•|ëŒ€ì •|ëª¨ìŠ¬í¬|í™”ìˆœ",
        "label": "ì¤‘ë¬¸Â·ì•ˆë• ì¼ëŒ€(ì„œê·€í¬ ì„œìª½)",
    },
    "ì„œê·€í¬ ì„œìª½": {
        "pattern": "ì¤‘ë¬¸|ì•ˆë•|ëŒ€ì •|ëª¨ìŠ¬í¬|í™”ìˆœ",
        "label": "ì„œê·€í¬ ì„œìª½(ì¤‘ë¬¸ ì¼ëŒ€)",
    },

    # ì„œê·€í¬ ë™ìª½ (ì„±ì‚°/í‘œì„ /ë‚¨ì›)
    "ì„±ì‚°": {
        "pattern": "ì„±ì‚°|í‘œì„ |ë‚¨ì›",
        "label": "ì„±ì‚°Â·í‘œì„  ì¼ëŒ€(ì„œê·€í¬ ë™ìª½)",
    },
    "ì„œê·€í¬ ë™ìª½": {
        "pattern": "ì„±ì‚°|í‘œì„ |ë‚¨ì›",
        "label": "ì„œê·€í¬ ë™ìª½(ì„±ì‚° ì¼ëŒ€)",
    },

    # ì‹œ ë‹¨ìœ„
    "ì œì£¼ì‹œ": {
        "pattern": "ì œì£¼ì‹œ",
        "label": "ì œì£¼ì‹œ ì „ì—­",
    },
    "ì„œê·€í¬ì‹œ": {
        "pattern": "ì„œê·€í¬ì‹œ",
        "label": "ì„œê·€í¬ì‹œ ì „ì—­",
    },
}

def parse_chat_message(message: str):
    """
    ê¸°ì¡´ /chat ì—ì„œ ì“°ë˜ ê°„ë‹¨ íŒŒì„œ.
    - tags, region_filter(ì •ê·œì‹ íŒ¨í„´), region_label, days, max_places_per_day, start_time_str
    (start_time_strëŠ” ì§€ê¸ˆì€ ì•ˆ ì“°ì§€ë§Œ ê·¸ëŒ€ë¡œ ë‘ )
    """
    msg = (message or "").strip()

    # 1) ê¸°ë³¸ê°’
    tags: List[str] = []
    region_filter: Optional[str] = None
    region_label: Optional[str] = None
    days = 1
    max_places_per_day = 3
    start_time_str = "09:00"

    # 2) ì¼ìˆ˜ íŒŒì‹± (2ë°•3ì¼ / 1ë°•2ì¼ / 3ì¼ ì½”ìŠ¤ ë“±)
    m = re.search(r"(\d+)\s*ë°•\s*(\d+)\s*ì¼", msg)
    if m:
        days = int(m.group(2))
    else:
        m2 = re.search(r"(\d+)\s*ì¼", msg)
        if m2:
            d = int(m2.group(1))
            days = max(1, min(int(d), 5))
    if "ë‹¹ì¼" in msg or "ì›ë°ì´" in msg:
        days = 1

    # 3) íƒœê·¸ íŒŒì‹±
    for kw, tag in KEYWORD_TO_TAG.items():
        if kw in msg and tag not in tags:
            tags.append(tag)

    # 4) ì§€ì—­ íŒŒì‹±
    for key, info in AREA_KEYWORDS.items():
        if key in msg:
            region_filter = info["pattern"]
            region_label = info["label"]
            break

    # 5) ì‹œê°„ëŒ€ (ì§€ê¸ˆì€ ì‚¬ìš© X, ê°’ë§Œ ìœ ì§€)
    if "ì˜¤í›„" in msg or "ëŠ¦ê²Œ" in msg or "ì ì‹¬" in msg:
        start_time_str = "11:00"
    if "ì•„ì¹¨ ì¼ì°" in msg or "ì¼ì¶œ" in msg:
        start_time_str = "07:00"

    # 6) ì—¬í–‰ ì¼ìˆ˜ì— ë”°ë¼ í•˜ë£¨ ê´€ê´‘ì§€ ê°œìˆ˜ ì¡°ì •
    if days >= 3:
        max_places_per_day = 4
    elif days == 1:
        max_places_per_day = 3
    else:
        max_places_per_day = 3

    return {
        "tags": tags,
        "region_filter": region_filter,
        "region_label": region_label,
        "days": days,
        "max_places_per_day": max_places_per_day,
        "start_time_str": start_time_str,
    }

# ------------------------------------------------
# 8-2. ì½”ìŠ¤ ì „ìš© ë£° ê¸°ë°˜ ì‘ë‹µ (ë™/ì„œ/ë‚¨/ë¶/2ë°•3ì¼)
# ------------------------------------------------

CourseDayRB = Dict[str, object]  # {"day": int, "title": str, "items": List[dict]]

COURSE_ITINERARY_RB: Dict[str, List[CourseDayRB]] = {
    "east": [
        {
            "day": 1,
            "title": "1ì¼ì°¨: ì œì£¼ ë™ìª½ í•µì‹¬ ì½”ìŠ¤",
            "items": [
                {
                    "time_label": "ì˜¤ì „",
                    "title": "ì¼ì¶œ & ì„±ì‚° ì „ë§ ì¦ê¸°ê¸°",
                    "spot_name": "ì„±ì‚°ì¼ì¶œë´‰",
                    "description": "ì„±ì‚°ì¼ì¶œë´‰ì— ì˜¬ë¼ ì¼ì¶œ ë˜ëŠ” íƒ íŠ¸ì¸ ë°”ë‹¤ ë·° ê°ìƒ.",
                },
                {
                    "time_label": "ì ì‹¬",
                    "title": "ì„±ì‚° ì¸ê·¼ ë§›ì§‘ì—ì„œ ì‹ì‚¬",
                    "spot_name": None,
                    "description": "ì„±ì‚°í•­ ê·¼ì²˜ ì‹ë‹¹ì—ì„œ í•´ì‚°ë¬¼ ìœ„ì£¼ë¡œ ì—¬ìœ  ìˆê²Œ ì ì‹¬.",
                },
                {
                    "time_label": "ì˜¤í›„",
                    "title": "ë°”ë‹¤ ì‚°ì±… & ì‹¤ë‚´ ì²´í—˜",
                    "spot_name": "ì„­ì§€ì½”ì§€",
                    "description": "ì„­ì§€ì½”ì§€ ì‚°ì±… í›„ ì•„ì¿ ì•„í”Œë¼ë„·ì œì£¼ì—ì„œ ì‹¤ë‚´ ì²´í—˜.",
                },
                {
                    "time_label": "ì˜¤í›„",
                    "title": "ì¹´í˜ íƒ€ì„",
                    "spot_name": "ë“œë¥´ì¿°ë‹¤inì„±ì‚°",
                    "description": "ë“œë¥´ì¿°ë‹¤inì„±ì‚°ì—ì„œ ë””ì €íŠ¸ì™€ í•¨ê»˜ íœ´ì‹.",
                },
                {
                    "time_label": "ì €ë…",
                    "title": "ìš°ë„ ë“œë¼ì´ë¸Œ ë˜ëŠ” í•´ì•ˆë„ë¡œ ì‚°ì±…",
                    "spot_name": "ìš°ë„",
                    "description": "ë°° ì‹œê°„ì„ ë§ì¶° ìš°ë„ë¥¼ ë‹¤ë…€ì˜¤ê±°ë‚˜ ì„±ì‚° ì¼ëŒ€ í•´ì•ˆ ë“œë¼ì´ë¸Œ.",
                },
            ],
        }
    ],
    "west": [
        {
            "day": 1,
            "title": "1ì¼ì°¨: ê°ì„± ê°€ë“ ì„œìª½ ì½”ìŠ¤",
            "items": [
                {
                    "time_label": "ì˜¤ì „",
                    "title": "ë…¹ì°¨ë°­ê³¼ ì „ì‹œ ê´€ëŒ",
                    "spot_name": "ì˜¤ì„¤ë¡ í‹° ë®¤ì§€ì—„",
                    "description": "ì˜¤ì„¤ë¡ í‹° ë®¤ì§€ì—„ì—ì„œ ì œì£¼ ë…¹ì°¨ë°­ê³¼ ì „ì‹œ ê°ìƒ.",
                },
                {
                    "time_label": "ì ì‹¬",
                    "title": "ì„œìª½ ì§€ì—­ ì‹ë‹¹ì—ì„œ ì ì‹¬",
                    "spot_name": None,
                    "description": "í˜‘ì¬/í•œë¦¼ ì¼ëŒ€ì—ì„œ í•œì‹ ë˜ëŠ” í•´ì‚°ë¬¼ ì‹ì‚¬.",
                },
                {
                    "time_label": "ì˜¤í›„",
                    "title": "ì˜¤ë¦„ & ëª©ì¥ ì¹´í˜",
                    "spot_name": "ìƒˆë³„ì˜¤ë¦„",
                    "description": "ìƒˆë³„ì˜¤ë¦„ì—ì„œ ê°€ë²¼ìš´ íŠ¸ë ˆí‚¹ í›„ ëª©ì¥ì¹´í˜ ë“œë¥´ì¿°ë‹¤ì—ì„œ íœ´ì‹.",
                },
                {
                    "time_label": "ì˜¤í›„",
                    "title": "í…Œë§ˆíŒŒí¬ ì·¨í–¥ ì €ê²©",
                    "spot_name": "ìŠ¤ëˆ„í”¼ê°€ë“ ",
                    "description": "ìŠ¤ëˆ„í”¼ê°€ë“  ë˜ëŠ” ì‹ í™”í…Œë§ˆíŒŒí¬ ì¤‘ ì·¨í–¥ì— ë§ê²Œ ì„ íƒ ë°©ë¬¸.",
                },
                {
                    "time_label": "ì €ë…",
                    "title": "ì„œìª½ ë°”ë‹¤ ì„ ì…‹ ì¦ê¸°ê¸°",
                    "spot_name": "ê³½ì§€í•´ìˆ˜ìš•ì¥",
                    "description": "ê³½ì§€í•´ìˆ˜ìš•ì¥Â·ê¸ˆëŠ¥í•´ìˆ˜ìš•ì¥ì—ì„œ ë…¸ì„ ê°ìƒ í›„ ì¹´í˜ ë˜ëŠ” ìˆ™ì†Œë¡œ ì´ë™.",
                },
            ],
        }
    ],
    "south": [
        {
            "day": 1,
            "title": "1ì¼ì°¨: ì¤‘ë¬¸Â·ì„œê·€í¬ ë‚¨ìª½ ì½”ìŠ¤",
            "items": [
                {
                    "time_label": "ì˜¤ì „",
                    "title": "ì œì£¼ ë‚¨ìª½ ë°”ë‹¤ í’ê²½",
                    "spot_name": "ì‚°ë°©ì‚°",
                    "description": "ì‚°ë°©ì‚°ê³¼ ìš©ë¨¸ë¦¬í•´ì•ˆ ì¼ëŒ€ë¥¼ í•¨ê»˜ ë‘˜ëŸ¬ë³´ë©° í•´ì•ˆ ì ˆê²½ ê°ìƒ.",
                },
                {
                    "time_label": "ì ì‹¬",
                    "title": "ì¤‘ë¬¸Â·ì„œê·€í¬ ì‹ë‹¹ì—ì„œ ì ì‹¬",
                    "spot_name": None,
                    "description": "í•´ì‚°ë¬¼ ë˜ëŠ” í‘ë¼ì§€ ë“±ìœ¼ë¡œ ë“ ë“ í•˜ê²Œ ì ì‹¬.",
                },
                {
                    "time_label": "ì˜¤í›„",
                    "title": "í­í¬ & ê°•ê°€ ì‚°ì±…",
                    "spot_name": "ì²œì§€ì—°í­í¬",
                    "description": "ì²œì§€ì—°í­í¬ì™€ ì‡ ì†Œê¹ì„ ë°©ë¬¸í•´ ë‚¨ìª½ì˜ ë¬¼ê°€ í’ê²½ ì¦ê¸°ê¸°.",
                },
                {
                    "time_label": "ì €ë…",
                    "title": "ë§ˆë¼ë„ ë˜ëŠ” ì„œê·€í¬ ì‹œë‚´",
                    "spot_name": "ë§ˆë¼ë„",
                    "description": "ë°° ì‹œê°„ì„ ë§ì¶° ë§ˆë¼ë„ë¥¼ ë‹¤ë…€ì˜¤ê±°ë‚˜ ì„œê·€í¬ ì‹œë‚´ ì‚°ì±….",
                },
            ],
        }
    ],
    "north": [
        {
            "day": 1,
            "title": "1ì¼ì°¨: ì œì£¼ì‹œÂ·êµ¬ì¢Œ ë¶ìª½ ì½”ìŠ¤",
            "items": [
                {
                    "time_label": "ì˜¤ì „",
                    "title": "ê³µí•­ ê·¼ì²˜ í•´ì•ˆ ë“œë¼ì´ë¸Œ",
                    "spot_name": "ë„ë‘ë™ ë¬´ì§€ê°œ í•´ì•ˆë„ë¡œ",
                    "description": "ë„ë‘ë™ ë¬´ì§€ê°œ í•´ì•ˆë„ë¡œë¥¼ ë”°ë¼ ê°€ë³ê²Œ ì‚°ì±…í•˜ë©° ë°”ë‹¤ ë·° ê°ìƒ.",
                },
                {
                    "time_label": "ì ì‹¬",
                    "title": "ì œì£¼ì‹œë‚´ ì‹ì‚¬",
                    "spot_name": None,
                    "description": "ì œì£¼ì‹œ ë‚´ ì‹ë‹¹ì—ì„œ í•œì‹/ë¶„ì‹ ë“± ê°„ë‹¨íˆ ì ì‹¬.",
                },
                {
                    "time_label": "ì˜¤í›„",
                    "title": "ë°•ë¬¼ê´€ & ë°”ë‹¤",
                    "spot_name": "ë„¥ìŠ¨ì»´í“¨í„°ë°•ë¬¼ê´€",
                    "description": "ë„¥ìŠ¨ì»´í“¨í„°ë°•ë¬¼ê´€ ê´€ëŒ í›„, ì‚¼ì–‘í•´ìˆ˜ìš•ì¥Â·ê¹€ë…•í•´ìˆ˜ìš•ì¥ ë°©ë¬¸.",
                },
                {
                    "time_label": "ì €ë…",
                    "title": "ì‹œë‚´ ì•¼ê²½ & ì•¼ì‹œì¥",
                    "spot_name": "ë™ë¬¸ì¬ë˜ì‹œì¥",
                    "description": "ê´€ë•ì • ê·¼ì²˜ ì‚°ì±… í›„ ë™ë¬¸ì¬ë˜ì‹œì¥ì—ì„œ ì•¼ì‹œì¥ ë¨¹ê±°ë¦¬ ì¦ê¸°ê¸°.",
                },
            ],
        }
    ],
}

COURSE_KO_NAME_RB: Dict[str, str] = {
    "east": "ì œì£¼ ë™ìª½ ì½”ìŠ¤",
    "west": "ì œì£¼ ì„œìª½ ì½”ìŠ¤",
    "south": "ì œì£¼ ë‚¨ìª½ ì½”ìŠ¤",
    "north": "ì œì£¼ ë¶ìª½ ì½”ìŠ¤",
}

def _format_course_days_rb(days: List[CourseDayRB]) -> str:
    lines: List[str] = []
    for day in days:
        lines.append(f"ğŸ“… {day['title']}")
        for item in day["items"]:
            spot_part = f" ({item['spot_name']})" if item.get("spot_name") else ""
            lines.append(f" - {item['time_label']}: {item['title']}{spot_part}")
            if item.get("description"):
                lines.append(f"   Â· {item['description']}")
        lines.append("")
    return "\n".join(lines).strip()

def _build_single_course_answer(course_key: str) -> Optional[str]:
    if course_key not in COURSE_ITINERARY_RB:
        return None
    title = COURSE_KO_NAME_RB.get(course_key, "")
    body = _format_course_days_rb(COURSE_ITINERARY_RB[course_key])
    return f"ğŸ—º {title} ì¶”ì²œ ì¼ì •ì´ì—ìš”.\n\n{body}"

def _build_2n3d_answer() -> str:
    """
    2ë°• 3ì¼ ê¸°ë³¸ ë£¨íŠ¸ ì˜ˆì‹œ:
    1ì¼ì°¨ ì„œìª½ â†’ 2ì¼ì°¨ ë‚¨ìª½ â†’ 3ì¼ì°¨ ë™ìª½
    """
    order = ["west", "south", "east"]
    lines: List[str] = []
    lines.append("â›± 2ë°• 3ì¼ ì œì£¼ë„ ì¶”ì²œ ì½”ìŠ¤ì˜ˆìš”.")
    lines.append("ì˜ˆì‹œ ë£¨íŠ¸: 1ì¼ì°¨ ì„œìª½ â†’ 2ì¼ì°¨ ë‚¨ìª½ â†’ 3ì¼ì°¨ ë™ìª½\n")

    day_num = 1
    for key in order:
        days = COURSE_ITINERARY_RB.get(key)
        if not days:
            continue
        d = days[0]
        lines.append(f"ğŸ“… {day_num}ì¼ì°¨: {COURSE_KO_NAME_RB.get(key, d['title'])}")
        for item in d["items"]:
            spot_part = f" ({item['spot_name']})" if item.get("spot_name") else ""
            lines.append(f" - {item['time_label']}: {item['title']}{spot_part}")
        lines.append("")
        day_num += 1

    lines.append("ì›í•˜ë©´ ì´ ì½”ìŠ¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìˆ™ì†ŒÂ·ì‹ë‹¹ê¹Œì§€ ê°™ì´ ì¶”ì²œí•´ ì¤„ê²Œìš”.")
    return "\n".join(lines).strip()

def rule_based_course_answer(user_message: str) -> Optional[str]:
    """
    - 'ì œì£¼ ì„œìª½ ì½”ìŠ¤', 'ì œì£¼ì„œìª½ì½”ìŠ¤', 'ì„œìª½ ì¼ì • ì¶”ì²œ' ë“±
    - '2ë°•3ì¼ ì œì£¼ë„ ì½”ìŠ¤', 'ì œì£¼ 2ë°• 3ì¼ ì½”ìŠ¤' ë“±
    """
    if not user_message:
        return None

    msg_no_space = user_message.replace(" ", "")
    msg_no_space = msg_no_space.lower()

    # 2ë°• 3ì¼ íŒ¨í„´
    if (
        ("2ë°•3ì¼" in msg_no_space or ("2ë°•" in msg_no_space and "3ì¼" in msg_no_space))
        and "ì½”ìŠ¤" in msg_no_space
    ):
        return _build_2n3d_answer()

    # ë°©í–¥ë³„ ì½”ìŠ¤
    if "ì„œìª½" in msg_no_space and ("ì½”ìŠ¤" in msg_no_space or "ì¼ì •" in msg_no_space):
        return _build_single_course_answer("west")
    if "ë™ìª½" in msg_no_space and ("ì½”ìŠ¤" in msg_no_space or "ì¼ì •" in msg_no_space):
        return _build_single_course_answer("east")
    if "ë‚¨ìª½" in msg_no_space and ("ì½”ìŠ¤" in msg_no_space or "ì¼ì •" in msg_no_space):
        return _build_single_course_answer("south")
    if "ë¶ìª½" in msg_no_space and ("ì½”ìŠ¤" in msg_no_space or "ì¼ì •" in msg_no_space):
        return _build_single_course_answer("north")

    return None

# ------------------------------------------------
# 9. Pydantic ëª¨ë¸ (Request / Response)
# ------------------------------------------------

class RecommendRequest(BaseModel):
    tags: List[str] = []
    region: Optional[str] = None           # ì£¼ì†Œ í•„í„° (ex. ì œì£¼ì‹œ, ì„œê·€í¬ì‹œ, ì• ì›”, ì„±ì‚°...)
    days: int = 1
    max_places_per_day: int = 3
    freeText: Optional[str] = ""
    subregions: Optional[List[str]] = None # ["ì œì£¼ ì„œ", "ì„œê·€í¬ ì„œ"] ë“±

class ItineraryItem(BaseModel):
    day: int
    order_in_day: int
    name: str
    category: str          # "ê´€ê´‘" / "ì‹ì‚¬" / "ìˆ™ì†Œ"  â† ì‚¬ëŒ ì½ëŠ” ë¼ë²¨
    address: str
    region_city: str
    subregion: str
    tags: str
    descriptionShort: str
    similarity: float
    lat: Optional[float]
    lng: Optional[float]

class DayPlan(BaseModel):
    day: int
    items: List[ItineraryItem]

class RecommendResponse(BaseModel):
    days: List[DayPlan]

# ìì—°ì–´/í‚¤ì›Œë“œìš©
class RecommendTextRequest(BaseModel):
    query: str
    max_places_per_day: int = 3

class ParsedQuery(BaseModel):
    original: str
    days: int
    tags: List[str]
    region_address: Optional[str]
    region_subregions: Optional[List[str]]
    freeText: str

class RecommendTextResponse(BaseModel):
    parsed: ParsedQuery
    days: List[DayPlan]
    message: str           # âœ… ì±—ë´‡ì— ê·¸ëŒ€ë¡œ ì“¸ í•œêµ­ì–´ ë¬¸ì¥

# ì±—ë´‡ìš©
class ChatRequest(BaseModel):
    message: str

class ChatResponse(BaseModel):
    reply: str
    itinerary: RecommendResponse

# ------------------------------------------------
# 10. DataFrame -> Response ë³€í™˜
# ------------------------------------------------

def itinerary_df_to_days(itinerary_df: pd.DataFrame) -> List[DayPlan]:
    if itinerary_df.empty:
        return []

    days_result: List[DayPlan] = []

    for day in sorted(itinerary_df["day"].unique()):
        day_df = itinerary_df[itinerary_df["day"] == day].copy()
        day_df = day_df.sort_values("order_in_day")

        items: List[ItineraryItem] = []
        for _, row in day_df.iterrows():
            raw_cat = str(row["category"])
            label = CATEGORY_LABEL.get(raw_cat, "ê¸°íƒ€")  # place â†’ ê´€ê´‘ ì‹ìœ¼ë¡œ ë³€í™˜

            items.append(
                ItineraryItem(
                    day=int(row["day"]),
                    order_in_day=int(row["order_in_day"]),
                    name=str(row["name"]),
                    category=label,
                    address=str(row["address"]),
                    region_city=str(row["region_city"]),
                    subregion=str(row["subregion"]),
                    tags=str(row["tags"]),
                    descriptionShort=str(row["descriptionShort"]),
                    similarity=float(row["similarity"]),
                    lat=float(row["lat"]) if not pd.isna(row["lat"]) else None,
                    lng=float(row["lng"]) if not pd.isna(row["lng"]) else None,
                )
            )
        days_result.append(DayPlan(day=int(day), items=items))

    return days_result

def itinerary_df_to_recommend_response(itinerary_df: pd.DataFrame) -> RecommendResponse:
    return RecommendResponse(days=itinerary_df_to_days(itinerary_df))

# ------------------------------------------------
# 11. /recommend (êµ¬ì¡°í™”ëœ ìš”ì²­ìš©)
# ------------------------------------------------

@app.post("/recommend", response_model=RecommendResponse)
def recommend_endpoint(req: RecommendRequest):
    itinerary_df = recommend_itinerary_no_time(
        selected_tags=req.tags,
        region_filter_address=req.region,
        region_filter_subregions=req.subregions,
        days=req.days,
        max_places_per_day=req.max_places_per_day,
        free_text=req.freeText or "",
    )
    return itinerary_df_to_recommend_response(itinerary_df)

# ------------------------------------------------
# 12. /recommend_text (ìì—°ì–´/í‚¤ì›Œë“œ ì „ìš©)
# ------------------------------------------------

def format_itinerary_message(parsed: ParsedQuery, days: List[DayPlan]) -> str:
    """
    /recommend_text ìš© í•œêµ­ì–´ ìš”ì•½ ë¬¸ì¥
    (ì¥ì†Œ ì´ë¦„ ì˜†ì— categoryëŠ” í•œêµ­ì–´ ë¼ë²¨ë¡œ ë“¤ì–´ê°)
    """
    if not days:
        return (
            f'ìš”ì²­í•˜ì‹  "{parsed.original}" ì¡°ê±´ì— ë”± ë§ëŠ” ì½”ìŠ¤ë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš” ğŸ˜¢\n'
            "ì—¬í–‰ ì¼ìˆ˜ë‚˜ ì§€ì—­, ë¶„ìœ„ê¸° ì¡°ê±´ì„ ì¡°ê¸ˆë§Œ ì™„í™”í•´ì„œ ë‹¤ì‹œ ì•Œë ¤ì£¼ì‹œë©´\n"
            "ë” ì˜ ë§ëŠ” ì¼ì •ì„ ì¶”ì²œí•´ ë“œë¦´ê²Œìš”!"
        )

    header = f'ìš”ì²­í•˜ì‹  "{parsed.original}" ì¡°ê±´ì„ ë°”íƒ•ìœ¼ë¡œ ì½”ìŠ¤ë¥¼ ë§Œë“¤ì–´ ë´¤ì–´ìš” ğŸ˜Š'

    days_str = f"{parsed.days}ì¼ ì¼ì •"
    mood_tags = [t for t in parsed.tags if t not in ["ë§›ì§‘"]]
    if mood_tags:
        mood_str = " / ".join(mood_tags)
        subheader = f"{days_str} Â· {mood_str} ë¶„ìœ„ê¸°"
    else:
        subheader = days_str

    body_lines: List[str] = []
    for day_plan in sorted(days, key=lambda d: d.day):
        segments = []
        for item in sorted(day_plan.items, key=lambda x: x.order_in_day):
            # ì´ë¦„ë§Œ ì“°ê³  ì‹¶ìœ¼ë©´ f"{item.name}" ë§Œ ë‚¨ê²¨ë„ ë¨
            segments.append(f"{item.name}({item.category})")
        line = f"{day_plan.day}ì¼ì°¨ : " + " â†’ ".join(segments)
        body_lines.append(line)

    footer = "ì„¸ë¶€ ì¼ì •ì€ ìˆœì„œëŒ€ë¡œ ì°¸ê³ í•˜ì‹œê³ , ì‹œê°„ì€ ììœ ë¡­ê²Œ ì¡°ì •í•´ ì£¼ì„¸ìš”!"

    return header + "\n" + subheader + "\n" + "\n".join(body_lines) + "\n" + footer

@app.post("/recommend_text", response_model=RecommendTextResponse)
def recommend_text_endpoint(req: RecommendTextRequest):
    parsed_raw = parse_user_query_advanced(req.query)

    itinerary_df = recommend_itinerary_no_time(
        selected_tags=parsed_raw["tags"],
        region_filter_address=parsed_raw["region_address"],
        region_filter_subregions=parsed_raw["region_subregions"],
        days=parsed_raw["days"],
        max_places_per_day=req.max_places_per_day,
        free_text=parsed_raw["freeText"],
    )

    days_plans = itinerary_df_to_days(itinerary_df)

    parsed_model = ParsedQuery(
        original=parsed_raw["original"],
        days=parsed_raw["days"],
        tags=parsed_raw["tags"],
        region_address=parsed_raw["region_address"],
        region_subregions=parsed_raw["region_subregions"],
        freeText=parsed_raw["freeText"],
    )

    message = format_itinerary_message(parsed_model, days_plans)

    return RecommendTextResponse(
        parsed=parsed_model,
        days=days_plans,
        message=message,
    )

# ------------------------------------------------
# 13. summarize_itinerary_for_chat + /chat ì—”ë“œí¬ì¸íŠ¸
# ------------------------------------------------

def summarize_itinerary_for_chat(resp: RecommendResponse, ctx: dict, original_message: str) -> str:
    """
    ì¶”ì²œ ê²°ê³¼ + íŒŒì‹±ëœ ì¡°ê±´(ctx)ì„ ë°”íƒ•ìœ¼ë¡œ
    ì‚¬ëŒì´ ì½ê¸° ì¢‹ì€ í•œê¸€ ì„¤ëª…ì„ ë§Œë“ ë‹¤.
    (ê° ì¥ì†Œì˜ ì‹œê°„ ì •ë³´ ì—†ì´ ìˆœì„œë§Œ ë³´ì—¬ì¤Œ)
    """
    if not resp.days:
        return "ì¡°ê±´ì— ë§ëŠ” ì½”ìŠ¤ë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš”. ë‚ ì§œ/ì§€ì—­/ì›í•˜ëŠ” ë¶„ìœ„ê¸°ë¥¼ ì¡°ê¸ˆ ë” ìì„¸íˆ ì•Œë ¤ì¤„ë˜ìš”?"

    desc_parts: List[str] = []

    # 1) ì‚¬ìš©ìê°€ ë³´ë‚¸ ë¬¸ì¥
    if original_message:
        desc_parts.append(f"ìš”ì²­í•˜ì‹  \"{original_message}\" ì¡°ê±´ì„ ë°”íƒ•ìœ¼ë¡œ ì½”ìŠ¤ë¥¼ ë§Œë“¤ì–´ ë´¤ì–´ìš” ğŸ˜Š")

    # 2) íŒŒì‹±ëœ ì¡°ê±´ ê°„ë‹¨ ìš”ì•½
    cond_parts: List[str] = []
    days = ctx.get("days")
    if days:
        cond_parts.append(f"{days}ì¼ ì¼ì •")

    region_label = ctx.get("region_label")
    if region_label:
        cond_parts.append(region_label)

    tags = ctx.get("tags") or []
    if tags:
        show_tags = tags[:3]
        cond_parts.append(" / ".join(show_tags) + " ë¶„ìœ„ê¸°")

    if cond_parts:
        desc_parts.append(" Â· ".join(cond_parts))

    # 3) ì¼ìë³„ ì½”ìŠ¤ ìš”ì•½
    lines: List[str] = []
    for day_plan in resp.days:
        items_text = " â†’ ".join(
            f"{item.name}({item.category})"
            for item in day_plan.items
        )
        lines.append(f"{day_plan.day}ì¼ì°¨ : {items_text}")

    desc_parts.extend(lines)
    desc_parts.append("ì„¸ë¶€ ì¼ì •ì€ ìˆœì„œëŒ€ë¡œ ì°¸ê³ í•´ì„œ ì‹œê°„ì€ ììœ ë¡­ê²Œ ì¡°ì •í•´ ì£¼ì„¸ìš”!")

    return "\n".join(desc_parts)

@app.post("/chat", response_model=ChatResponse)
def chat(req: ChatRequest):
    """
    1) ë£° ê¸°ë°˜ ì½”ìŠ¤(ë™/ì„œ/ë‚¨/ë¶, 2ë°•3ì¼) ë¨¼ì € ì²´í¬
    2) ì•„ë‹ˆë©´ parse_chat_messageë¡œ íŒŒì‹± í›„ recommend_itinerary_no_time ì‚¬ìš©
    """
    # 1) ë™/ì„œ/ë‚¨/ë¶/2ë°•3ì¼ ì½”ìŠ¤ ë£° ê¸°ë°˜ ì‘ë‹µ
    rb_answer = rule_based_course_answer(req.message)
    if rb_answer:
        empty_resp = RecommendResponse(days=[])
        return ChatResponse(reply=rb_answer, itinerary=empty_resp)

    # 2) ì¼ë°˜ ì½”ìŠ¤ ì¶”ì²œ ë¡œì§ (ë„¤ê°€ ì“°ë˜ parse_chat_message + ìƒˆ recommend_itinerary_no_time)
    ctx = parse_chat_message(req.message)

    itinerary_df = recommend_itinerary_no_time(
        selected_tags=ctx["tags"],
        region_filter_address=ctx["region_filter"],   # ì •ê·œì‹ íŒ¨í„´ì´ì§€ë§Œ str.contains ê¸°ë³¸ì´ regexë¼ ë™ì‘
        region_filter_subregions=None,
        days=ctx["days"],
        max_places_per_day=ctx["max_places_per_day"],
        free_text=req.message,
    )

    resp = itinerary_df_to_recommend_response(itinerary_df)
    reply_text = summarize_itinerary_for_chat(resp, ctx, req.message)

    return ChatResponse(
        reply=reply_text,
        itinerary=resp,
    )

# ------------------------------------------------
# ì‹¤í–‰ ë°©ë²• (í„°ë¯¸ë„)
# ------------------------------------------------
# uvicorn main:app --reload --port 8000
# http://127.0.0.1:8000/docs
#  - POST /recommend_text : "ì œì£¼ ì„œìª½ ë‹¹ì¼ì¹˜ê¸° ì½”ìŠ¤ ì¶”ì²œí•´ì¤˜"
#  - POST /chat : ì±—ë´‡ì²˜ëŸ¼ ëŒ€í™” ("ì»¤í”Œ 2ë°•3ì¼ ì„œê·€í¬ ë™ìª½ ì½”ìŠ¤ ì¶”ì²œí•´ì¤˜")
