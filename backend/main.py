# main.py
# ================================================
# ì œì£¼ ì—¬í–‰ ì½”ìŠ¤ ì¶”ì²œ API (ê´€ê´‘ + ìŒì‹ + ìˆ™ì†Œ, íƒ€ì„ë¼ì¸)
# + ì±—ë´‡ìš© /chat ì—”ë“œí¬ì¸íŠ¸
# ================================================

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional, Tuple, Dict
from datetime import datetime, timedelta

import pandas as pd
import numpy as np
import re

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import linear_kernel


# ------------------------------------------------
# 0. FastAPI ê¸°ë³¸ ì„¤ì •
# ------------------------------------------------

app = FastAPI(title="Jeju Trip Recommender API")

# í”„ë¡ íŠ¸ì—”ë“œ ë„ë©”ì¸/í¬íŠ¸ì— ë§ê²Œ ìˆ˜ì •í•´ë„ ë¨
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ì˜ˆ: ["http://localhost:5173"]
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.get("/")
def root():
    return {"status": "FastAPI is running!"}


# ------------------------------------------------
# 1. CSV ë¡œë“œ & ê¸°ë³¸ ì „ì²˜ë¦¬ (ì„œë²„ ì‹œì‘ ì‹œ 1ë²ˆë§Œ)
# ------------------------------------------------

CSV_PATH = "data/places_api.csv"

df = pd.read_csv(CSV_PATH)

for col in ["name", "type", "address", "lat", "lng", "keywords", "description"]:
    if col not in df.columns:
        if col in ["lat", "lng"]:
            df[col] = np.nan
        else:
            df[col] = ""

df["keywords"] = df["keywords"].fillna("")
df["description"] = df["description"].fillna("")
df["address"] = df["address"].fillna("")
df["type"] = df["type"].fillna("")

df["search_text"] = (
    df["keywords"].astype(str).str.replace("|", " ", regex=False)
    + " "
    + df["description"].astype(str)
)


# ------------------------------------------------
# 2. ì‹œ(ì œì£¼ì‹œ/ì„œê·€í¬ì‹œ) ì¶”ì¶œ & ì‚¬ë¶„ë©´ ë¶„ë¥˜
# ------------------------------------------------

def extract_region_city(address: str) -> str:
    if not isinstance(address, str):
        return "ê¸°íƒ€"
    if "ì œì£¼ì‹œ" in address:
        return "ì œì£¼ì‹œ"
    if "ì„œê·€í¬ì‹œ" in address:
        return "ì„œê·€í¬ì‹œ"
    return "ê¸°íƒ€"


df["region_city"] = df["address"].apply(extract_region_city)

jeju_mask = (df["region_city"] == "ì œì£¼ì‹œ") & df["lng"].notna()
seogwipo_mask = (df["region_city"] == "ì„œê·€í¬ì‹œ") & df["lng"].notna()

JEJU_LNG_MID = df.loc[jeju_mask, "lng"].median() if jeju_mask.any() else 126.6
SEOGWIPO_LNG_MID = df.loc[seogwipo_mask, "lng"].median() if seogwipo_mask.any() else 126.6

NAME_TO_SUBREGION = {
    # --- ì œì£¼ì‹œ ì„œìª½ ---
    "ì• ì›”": "ì œì£¼ ì„œ",
    "ì• ì›”ì": "ì œì£¼ ì„œ",
    "í•œë¦¼": "ì œì£¼ ì„œ",
    "í•œë¦¼ì": "ì œì£¼ ì„œ",
    "í˜‘ì¬": "ì œì£¼ ì„œ",
    "í•œê²½": "ì œì£¼ ì„œ",
    "í•œê²½ë©´": "ì œì£¼ ì„œ",
    "ê³ ì‚°": "ì œì£¼ ì„œ",
    "ì´í˜¸": "ì œì£¼ ì„œ",
    "ì´í˜¸ë™": "ì œì£¼ ì„œ",
    "ë„ë‘": "ì œì£¼ ì„œ",
    "ë„ë‘ë™": "ì œì£¼ ì„œ",

    # --- ì œì£¼ì‹œ ë™ìª½ ---
    "ì¡°ì²œ": "ì œì£¼ ë™",
    "ì¡°ì²œì": "ì œì£¼ ë™",
    "í•¨ë•": "ì œì£¼ ë™",
    "í•¨ë•ë¦¬": "ì œì£¼ ë™",
    "êµ¬ì¢Œ": "ì œì£¼ ë™",
    "êµ¬ì¢Œì": "ì œì£¼ ë™",
    "ê¹€ë…•": "ì œì£¼ ë™",
    "ê¹€ë…•ë¦¬": "ì œì£¼ ë™",
    "ì„¸í™”": "ì œì£¼ ë™",
    "ì›”ì •": "ì œì£¼ ë™",
    "í‰ëŒ€": "ì œì£¼ ë™",
    "ìš°ë„": "ì œì£¼ ë™",

    # --- ì„œê·€í¬ ë™ìª½ ---
    "ì„±ì‚°": "ì„œê·€í¬ ë™",
    "ì„±ì‚°ì": "ì„œê·€í¬ ë™",
    "í‘œì„ ": "ì„œê·€í¬ ë™",
    "í‘œì„ ë©´": "ì„œê·€í¬ ë™",
    "ë‚¨ì›": "ì„œê·€í¬ ë™",
    "ë‚¨ì›ì": "ì„œê·€í¬ ë™",

    # --- ì„œê·€í¬ ì„œìª½ ---
    "ì¤‘ë¬¸": "ì„œê·€í¬ ì„œ",
    "ì¤‘ë¬¸ë™": "ì„œê·€í¬ ì„œ",
    "ì•ˆë•": "ì„œê·€í¬ ì„œ",
    "ì•ˆë•ë©´": "ì„œê·€í¬ ì„œ",
    "ëŒ€ì •": "ì„œê·€í¬ ì„œ",
    "ëŒ€ì •ì": "ì„œê·€í¬ ì„œ",
    "ëª¨ìŠ¬í¬": "ì„œê·€í¬ ì„œ",
    "í™”ìˆœ": "ì„œê·€í¬ ì„œ",
}


def classify_subregion(row) -> str:
    addr = row.get("address", "")
    city = row.get("region_city", "ê¸°íƒ€")
    lng = row.get("lng", np.nan)

    # ì£¼ì†Œì—ì„œ ë™/ì/ë©´ í‚¤ì›Œë“œë¡œ ë¨¼ì € ë§¤í•‘
    if isinstance(addr, str):
        for name, sub in NAME_TO_SUBREGION.items():
            if name in addr:
                return sub

    # ì¢Œí‘œê°€ ì—†ìœ¼ë©´ ì‹œ ê¸°ì¤€ìœ¼ë¡œ ê¸°ë³¸ê°’
    if pd.isna(lng):
        if city == "ì œì£¼ì‹œ":
            return "ì œì£¼ ë™"
        elif city == "ì„œê·€í¬ì‹œ":
            return "ì„œê·€í¬ ë™"
        else:
            return "ê¸°íƒ€"

    # ì¢Œí‘œ ìˆìœ¼ë©´ ê²½ë„ ê¸°ì¤€ìœ¼ë¡œ ë™/ì„œ ë‚˜ëˆ„ê¸°
    if city == "ì œì£¼ì‹œ":
        return "ì œì£¼ ë™" if lng >= JEJU_LNG_MID else "ì œì£¼ ì„œ"
    elif city == "ì„œê·€í¬ì‹œ":
        return "ì„œê·€í¬ ë™" if lng >= SEOGWIPO_LNG_MID else "ì„œê·€í¬ ì„œ"
    else:
        return "ê¸°íƒ€"


df["subregion"] = df.apply(classify_subregion, axis=1)


# ------------------------------------------------
# 3. ì´ë™ì‹œê°„ ë§¤íŠ¸ë¦­ìŠ¤
# ------------------------------------------------

SUBREGIONS = ["ì œì£¼ ë™", "ì œì£¼ ì„œ", "ì„œê·€í¬ ë™", "ì„œê·€í¬ ì„œ", "ê¸°íƒ€"]
DEFAULT_TRAVEL_TIME = 1.0

travel_time_matrix = {
    "ì œì£¼ ë™": {
        "ì œì£¼ ë™": 0.3,
        "ì œì£¼ ì„œ": 1.0,
        "ì„œê·€í¬ ë™": 0.5,
        "ì„œê·€í¬ ì„œ": 1.5,
        "ê¸°íƒ€": 1.0,
    },
    "ì œì£¼ ì„œ": {
        "ì œì£¼ ë™": 1.0,
        "ì œì£¼ ì„œ": 0.3,
        "ì„œê·€í¬ ë™": 1.0,
        "ì„œê·€í¬ ì„œ": 0.5,
        "ê¸°íƒ€": 1.0,
    },
    "ì„œê·€í¬ ë™": {
        "ì œì£¼ ë™": 0.5,
        "ì œì£¼ ì„œ": 1.0,
        "ì„œê·€í¬ ë™": 0.3,
        "ì„œê·€í¬ ì„œ": 1.0,
        "ê¸°íƒ€": 1.0,
    },
    "ì„œê·€í¬ ì„œ": {
        "ì œì£¼ ë™": 1.5,
        "ì œì£¼ ì„œ": 0.5,
        "ì„œê·€í¬ ë™": 1.0,
        "ì„œê·€í¬ ì„œ": 0.3,
        "ê¸°íƒ€": 1.0,
    },
    "ê¸°íƒ€": {
        "ì œì£¼ ë™": 1.0,
        "ì œì£¼ ì„œ": 1.0,
        "ì„œê·€í¬ ë™": 1.0,
        "ì„œê·€í¬ ì„œ": 1.0,
        "ê¸°íƒ€": 0.5,
    },
}


def get_travel_time(sub1: str, sub2: str) -> float:
    t1 = travel_time_matrix.get(sub1, {})
    return t1.get(sub2, DEFAULT_TRAVEL_TIME)


# ------------------------------------------------
# 4. íƒœê·¸ / ì¿¼ë¦¬ í™•ì¥
# ------------------------------------------------

BASE_TAGS = [
    {"key": "íœ´ì‹", "icon": "ğŸ§˜"},
    {"key": "ì¹œêµ¬ë“¤", "icon": "ğŸ‘«"},
    {"key": "í˜¼ì", "icon": "ğŸ§­"},
    {"key": "ë¬¸í™”", "icon": "ğŸ›ï¸"},
    {"key": "ìì—°", "icon": "ğŸï¸"},
    {"key": "ì‚¬ì§„", "icon": "ğŸ“·"},
    {"key": "ë°˜ë ¤ë™ë¬¼ ë™ë°˜", "icon": "ğŸ¶"},
    {"key": "ê°€ì¡±ì—¬í–‰", "icon": "ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦"},
    {"key": "ì•¡í‹°ë¹„í‹°", "icon": "ğŸ¯"},
    {"key": "ë”ë³´ê¸°", "icon": "â•"},
]

STAY_TAGS = [
    {"key": "ëŸ­ì…”ë¦¬", "icon": "ğŸ’"},
    {"key": "íœ´ì‹", "icon": "ğŸ›Œ"},
    {"key": "ê°€ì¡±ì—¬í–‰", "icon": "ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦"},
    {"key": "ì»¤í”Œ", "icon": "ğŸ’‘"},
    {"key": "ì‚¬ì§„", "icon": "ğŸ“·"},
    {"key": "ë°˜ë ¤ë™ë¬¼ ë™ë°˜", "icon": "ğŸ¶"},
    {"key": "ìì—°", "icon": "ğŸï¸"},
    {"key": "ì˜¤ì…˜ë·°", "icon": "ğŸŒŠ"},
    {"key": "í’€ë¹Œë¼", "icon": "ğŸŠ"},
    {"key": "ë”ë³´ê¸°", "icon": "â•"},
]

FOOD_TAGS = [
    {"key": "í‘ë¼ì§€", "icon": "ğŸ·"},
    {"key": "ê³ ê¸°êµ­ìˆ˜", "icon": "ğŸœ"},
    {"key": "í•´ì¥êµ­", "icon": "ğŸ¥£"},
    {"key": "ì œì£¼í–¥í† ìŒì‹", "icon": "ğŸ²"},
    {"key": "í•´ì‚°ë¬¼", "icon": "ğŸŸ"},
    {"key": "í•œì‹", "icon": "ğŸ±"},
    {"key": "ì¼ì‹", "icon": "ğŸ£"},
    {"key": "ì¤‘ì‹", "icon": "ğŸ¥¡"},
    {"key": "ì–‘ì‹", "icon": "ğŸ"},
    {"key": "ë”ë³´ê¸°", "icon": "â•"},
]

ALL_TAG_KEYS = {t["key"] for t in (BASE_TAGS + STAY_TAGS + FOOD_TAGS)}

TAG_TO_QUERY_EXPANSION = {
    "íœ´ì‹": "íœ´ì‹ íë§ ì¡°ìš©í•œ í•œì í•œ ì—¬ìœ ",
    "ì¹œêµ¬ë“¤": "ì¹œêµ¬ ë™í–‰ ë‹¨ì²´ ëª¨ì„",
    "í˜¼ì": "í˜¼ì ì†”ë¡œ í˜¼ìì—¬í–‰ ì¡°ìš©í•œ",
    "ë¬¸í™”": "ë¬¸í™” ì „ì‹œ ê³µì—° ì—­ì‚¬ ë°•ë¬¼ê´€ ê°¤ëŸ¬ë¦¬",
    "ìì—°": "ìì—° ìˆ² ë°”ë‹¤ ì‚° ì˜¤ë¦„ ì „ë§ í’ê²½",
    "ì‚¬ì§„": "ì‚¬ì§„ í¬í†  í¬í† ìŠ¤íŒŸ ì¸ìƒìƒ· ë·° ì „ë§",
    "ë°˜ë ¤ë™ë¬¼ ë™ë°˜": "ë°˜ë ¤ë™ë¬¼ ë°˜ë ¤ê²¬ ì• ê²¬ ë™ë¬¼ ë™ë°˜",
    "ê°€ì¡±ì—¬í–‰": "ê°€ì¡± ê°€ì¡±ì—¬í–‰ ì•„ì´ ì–´ë¦°ì´ í‚¤ì¦ˆ",
    "ì•¡í‹°ë¹„í‹°": "ì•¡í‹°ë¹„í‹° ì²´í—˜ ì²´í—˜í™œë™ ë ˆì €",
    "ëŸ­ì…”ë¦¬": "ëŸ­ì…”ë¦¬ ê³ ê¸‰ í”„ë¦¬ë¯¸ì—„",
    "ì»¤í”Œ": "ì»¤í”Œ ì—°ì¸ ë¡œë§¨í‹± ë°ì´íŠ¸",
    "ì˜¤ì…˜ë·°": "ì˜¤ì…˜ë·° ë°”ë‹¤ë·° ë°”ë‹¤ì „ë§",
    "í’€ë¹Œë¼": "í’€ë¹Œë¼ ìˆ˜ì˜ì¥ í”„ë¼ì´ë¹—",
    "í‘ë¼ì§€": "í‘ë¼ì§€ ê³ ê¸° ì‚¼ê²¹ì‚´ êµ¬ì´",
    "ê³ ê¸°êµ­ìˆ˜": "ê³ ê¸°êµ­ìˆ˜ êµ­ìˆ˜ êµ­ë°¥",
    "í•´ì¥êµ­": "í•´ì¥êµ­ êµ­ë°¥",
    "ì œì£¼í–¥í† ìŒì‹": "í–¥í† ìŒì‹ ì œì£¼ìŒì‹ í† ì†ìŒì‹",
    "í•´ì‚°ë¬¼": "í•´ì‚°ë¬¼ íšŒ í•´ë¬¼ ìƒì„ ",
    "í•œì‹": "í•œì‹ ë°±ë°˜ ì‹ë‹¹",
    "ì¼ì‹": "ì¼ì‹ ì´ˆë°¥ ìŠ¤ì‹œ",
    "ì¤‘ì‹": "ì¤‘ì‹ ì¤‘êµ­ì§‘ ì§œì¥ ì§¬ë½•",
    "ì–‘ì‹": "ì–‘ì‹ íŒŒìŠ¤íƒ€ í”¼ì ìŠ¤í…Œì´í¬",
}


def extract_tags_from_free_text(free_text: str) -> List[str]:
    if not free_text:
        return []
    tokens = re.split(r"[\s,]+", free_text.strip())
    extra_tags = set()
    for token in tokens:
        if not token:
            continue
        for tag in ALL_TAG_KEYS:
            if tag in token or token in tag:
                extra_tags.add(tag)
    return list(extra_tags)


def build_query_from_tags(selected_tags: List[str], free_text: str = "") -> Tuple[str, List[str]]:
    extra_tags = extract_tags_from_free_text(free_text)
    merged_tags = list(set(selected_tags) | set(extra_tags))

    tokens: List[str] = []
    for tag in merged_tags:
        tag = tag.strip()
        if not tag:
            continue
        tokens.append(tag)
        if tag in TAG_TO_QUERY_EXPANSION:
            tokens.append(TAG_TO_QUERY_EXPANSION[tag])

    if free_text:
        tokens.append(free_text)

    query_text = " ".join(tokens)
    return query_text, merged_tags

# ------------------------------------------------
# 4-1. ì±—ë´‡ìš© í‚¤ì›Œë“œ â†’ íƒœê·¸/ì§€ì—­/ê¸°ê°„ íŒŒì„œ
# ------------------------------------------------

# ì‚¬ìš©ìê°€ ì“°ëŠ” ë‹¨ì–´ â†’ ìš°ë¦¬ ì‹œìŠ¤í…œ íƒœê·¸ë¡œ ë§¤í•‘
KEYWORD_TO_TAG = {
    # ë™í–‰ / ë¶„ìœ„ê¸°
    "ì»¤í”Œ": "ì»¤í”Œ",
    "ë°ì´íŠ¸": "ì»¤í”Œ",
    "ì‹ í˜¼": "ì»¤í”Œ",
    "í—ˆë‹ˆë¬¸": "ì»¤í”Œ",
    "ë¶€ë¶€": "ì»¤í”Œ",

    "ê°€ì¡±": "ê°€ì¡±ì—¬í–‰",
    "ì•„ì´": "ê°€ì¡±ì—¬í–‰",
    "í‚¤ì¦ˆ": "ê°€ì¡±ì—¬í–‰",
    "ì• ë“¤": "ê°€ì¡±ì—¬í–‰",

    "í˜¼ì": "í˜¼ì",
    "í˜¼í–‰": "í˜¼ì",

    # ë¶„ìœ„ê¸° / í™œë™
    "íë§": "íœ´ì‹",
    "ì‰¬ê³ ": "íœ´ì‹",
    "íœ´ì‹": "íœ´ì‹",
    "ì¹´í˜": "íœ´ì‹",
    "ì¹´ê³µ": "íœ´ì‹",

    "ë°”ë‹¤": "ìì—°",
    "í•´ë³€": "ìì—°",
    "í•´ìˆ˜ìš•ì¥": "ìì—°",
    "ì˜¤ì…˜ë·°": "ì˜¤ì…˜ë·°",
    "ë·°ë§›ì§‘": "ì‚¬ì§„",
    "ì‚¬ì§„": "ì‚¬ì§„",
    "í¬í† ": "ì‚¬ì§„",
    "ì¸ìƒìƒ·": "ì‚¬ì§„",

    "ì˜¤ë¦„": "ìì—°",
    "ì‚°": "ìì—°",
    "ìˆ²": "ìì—°",

    # ìŒì‹ ì·¨í–¥
    "í‘ë¼ì§€": "í‘ë¼ì§€",
    "ê³ ê¸°êµ­ìˆ˜": "ê³ ê¸°êµ­ìˆ˜",
    "í•´ì‚°ë¬¼": "í•´ì‚°ë¬¼",
    "íšŒ": "í•´ì‚°ë¬¼",
    "í–¥í† ìŒì‹": "ì œì£¼í–¥í† ìŒì‹",
}

# ì‚¬ìš©ìê°€ ë§í•˜ëŠ” í° ì§€ì—­ í‚¤ì›Œë“œ â†’ address í•„í„°ìš© íŒ¨í„´ + ì‚¬ëŒí•œí…Œ ë³´ì—¬ì¤„ ë¼ë²¨
AREA_KEYWORDS = {
    # ì œì£¼ì‹œ ì„œìª½ (ì• ì›”/í•œë¦¼/í˜‘ì¬/í•œê²½/ì´í˜¸/ë„ë‘)
    "ì œì£¼ ì„œìª½": {
        "pattern": "ì• ì›”|í•œë¦¼|í˜‘ì¬|í•œê²½|ì´í˜¸|ë„ë‘",
        "label": "ì œì£¼ì‹œ ì„œìª½(ì• ì›”Â·í•œë¦¼Â·í˜‘ì¬ ì¼ëŒ€)",
    },
    "ì• ì›”": {
        "pattern": "ì• ì›”",
        "label": "ì• ì›” ì¼ëŒ€",
    },
    "í•œë¦¼": {
        "pattern": "í•œë¦¼|í˜‘ì¬",
        "label": "í•œë¦¼Â·í˜‘ì¬ ì¼ëŒ€",
    },

    # ì œì£¼ì‹œ ë™ìª½
    "ì œì£¼ ë™ìª½": {
        "pattern": "ì¡°ì²œ|í•¨ë•|êµ¬ì¢Œ|ê¹€ë…•|ì„¸í™”|ì›”ì •|í‰ëŒ€|ìš°ë„",
        "label": "ì œì£¼ì‹œ ë™ìª½(í•¨ë•Â·êµ¬ì¢Œ ì¼ëŒ€)",
    },

    # ì„œê·€í¬ ì„œìª½ (ì¤‘ë¬¸/ì•ˆë•/ëŒ€ì •/ëª¨ìŠ¬í¬/í™”ìˆœ)
    "ì¤‘ë¬¸": {
        "pattern": "ì¤‘ë¬¸|ì•ˆë•|ëŒ€ì •|ëª¨ìŠ¬í¬|í™”ìˆœ",
        "label": "ì¤‘ë¬¸Â·ì•ˆë• ì¼ëŒ€(ì„œê·€í¬ ì„œìª½)",
    },
    "ì„œê·€í¬ ì„œìª½": {
        "pattern": "ì¤‘ë¬¸|ì•ˆë•|ëŒ€ì •|ëª¨ìŠ¬í¬|í™”ìˆœ",
        "label": "ì„œê·€í¬ ì„œìª½(ì¤‘ë¬¸ ì¼ëŒ€)",
    },

    # ì„œê·€í¬ ë™ìª½ (ì„±ì‚°/í‘œì„ /ë‚¨ì›)
    "ì„±ì‚°": {
        "pattern": "ì„±ì‚°|í‘œì„ |ë‚¨ì›",
        "label": "ì„±ì‚°Â·í‘œì„  ì¼ëŒ€(ì„œê·€í¬ ë™ìª½)",
    },
    "ì„œê·€í¬ ë™ìª½": {
        "pattern": "ì„±ì‚°|í‘œì„ |ë‚¨ì›",
        "label": "ì„œê·€í¬ ë™ìª½(ì„±ì‚° ì¼ëŒ€)",
    },

    # ì‹œ ë‹¨ìœ„
    "ì œì£¼ì‹œ": {
        "pattern": "ì œì£¼ì‹œ",
        "label": "ì œì£¼ì‹œ ì „ì—­",
    },
    "ì„œê·€í¬ì‹œ": {
        "pattern": "ì„œê·€í¬ì‹œ",
        "label": "ì„œê·€í¬ì‹œ ì „ì—­",
    },
}
def parse_chat_message(message: str):
    """
    ì‚¬ìš©ìê°€ ë³´ë‚¸ ìì—°ì–´ ë¬¸ì¥ì„ ë¶„ì„í•´ì„œ
    - tags: ["ì»¤í”Œ", "ìì—°", "ì˜¤ì…˜ë·°", ...]
    - region_filter: ì£¼ì†Œ í•„í„°ìš© ì •ê·œì‹ íŒ¨í„´ (ì˜ˆ: "ì• ì›”|í•œë¦¼|í˜‘ì¬")
    - region_label: ì‚¬ëŒì´ ì½ì„ ì˜ˆìœ ì„¤ëª… (ì˜ˆ: "ì œì£¼ì‹œ ì„œìª½(ì• ì›”Â·í•œë¦¼Â·í˜‘ì¬ ì¼ëŒ€)")
    - days: ì—¬í–‰ ì¼ìˆ˜
    - max_places_per_day: í•˜ë£¨ ê´€ê´‘ì§€ ê°œìˆ˜
    - start_time_str: ì‹œì‘ ì‹œê°„
    ë¥¼ ì¶”ì¶œí•œë‹¤.
    """
    msg = (message or "").strip()

    # 1) ê¸°ë³¸ê°’
    tags: List[str] = []
    region_filter: Optional[str] = None
    region_label: Optional[str] = None
    days = 1
    max_places_per_day = 3
    start_time_str = "09:00"

    # 2) ì¼ìˆ˜ íŒŒì‹± (2ë°•3ì¼ / 1ë°• 2ì¼ / 3ì¼ ì½”ìŠ¤ ë“±)
    m = re.search(r"(\d+)\s*ë°•\s*(\d+)\s*ì¼", msg)
    if m:
        # "2ë°•3ì¼"ì´ë©´ 3ì¼
        days = int(m.group(2))
    else:
        m2 = re.search(r"(\d+)\s*ì¼", msg)
        if m2:
            d = int(m2.group(1))
            # 1~5ì¼ ì‚¬ì´ë¡œ ì œí•œ
            days = max(1, min(int(d), 5))
    if "ë‹¹ì¼" in msg or "ì›ë°ì´" in msg:
        days = 1

    # 3) íƒœê·¸ íŒŒì‹±
    for kw, tag in KEYWORD_TO_TAG.items():
        if kw in msg and tag not in tags:
            tags.append(tag)

    # 4) ì§€ì—­ íŒŒì‹±
    for key, info in AREA_KEYWORDS.items():
        if key in msg:
            region_filter = info["pattern"]
            region_label = info["label"]
            break

    # 5) ì‹œê°„ëŒ€ (ëŒ€ì¶©ë§Œ ì²˜ë¦¬)
    if "ì˜¤í›„" in msg or "ëŠ¦ê²Œ" in msg or "ì ì‹¬" in msg:
        start_time_str = "11:00"
    if "ì•„ì¹¨ ì¼ì°" in msg or "ì¼ì¶œ" in msg:
        start_time_str = "07:00"

    # 6) ì—¬í–‰ ì¼ìˆ˜ì— ë”°ë¼ í•˜ë£¨ ê´€ê´‘ì§€ ê°œìˆ˜ ì¡°ì •
    if days >= 3:
        max_places_per_day = 4
    elif days == 1:
        max_places_per_day = 3
    else:
        max_places_per_day = 3

    return {
        "tags": tags,
        "region_filter": region_filter,
        "region_label": region_label,
        "days": days,
        "max_places_per_day": max_places_per_day,
        "start_time_str": start_time_str,
    }

# ------------------------------------------------
# 4-2. ì½”ìŠ¤ ì „ìš© ë£° ê¸°ë°˜ ì‘ë‹µ (ì±—ë´‡)
#      - "ì œì£¼ ì„œìª½ ì½”ìŠ¤", "ì œì£¼ë™ìª½ì½”ìŠ¤", "2ë°•3ì¼ ì œì£¼ë„ ì½”ìŠ¤" ë“±
# ------------------------------------------------

# í”„ë¡ íŠ¸ì—ì„œ ë§Œë“  ì½”ìŠ¤ ì¼ì •ê³¼ ë™ì¼í•œ ëŠë‚Œìœ¼ë¡œ êµ¬ì„±
CourseDayRB = Dict[str, object]  # {"day": int, "title": str, "items": List[dict]]

COURSE_ITINERARY_RB: Dict[str, List[CourseDayRB]] = {
    "east": [
        {
            "day": 1,
            "title": "1ì¼ì°¨: ì œì£¼ ë™ìª½ í•µì‹¬ ì½”ìŠ¤",
            "items": [
                {
                    "time_label": "ì˜¤ì „",
                    "title": "ì¼ì¶œ & ì„±ì‚° ì „ë§ ì¦ê¸°ê¸°",
                    "spot_name": "ì„±ì‚°ì¼ì¶œë´‰",
                    "description": "ì„±ì‚°ì¼ì¶œë´‰ì— ì˜¬ë¼ ì¼ì¶œ ë˜ëŠ” íƒ íŠ¸ì¸ ë°”ë‹¤ ë·° ê°ìƒ.",
                },
                {
                    "time_label": "ì ì‹¬",
                    "title": "ì„±ì‚° ì¸ê·¼ ë§›ì§‘ì—ì„œ ì‹ì‚¬",
                    "spot_name": None,
                    "description": "ì„±ì‚°í•­ ê·¼ì²˜ ì‹ë‹¹ì—ì„œ í•´ì‚°ë¬¼ ìœ„ì£¼ë¡œ ì—¬ìœ  ìˆê²Œ ì ì‹¬.",
                },
                {
                    "time_label": "ì˜¤í›„",
                    "title": "ë°”ë‹¤ ì‚°ì±… & ì‹¤ë‚´ ì²´í—˜",
                    "spot_name": "ì„­ì§€ì½”ì§€",
                    "description": "ì„­ì§€ì½”ì§€ ì‚°ì±… í›„ ì•„ì¿ ì•„í”Œë¼ë„·ì œì£¼ì—ì„œ ì‹¤ë‚´ ì²´í—˜.",
                },
                {
                    "time_label": "ì˜¤í›„",
                    "title": "ì¹´í˜ íƒ€ì„",
                    "spot_name": "ë“œë¥´ì¿°ë‹¤inì„±ì‚°",
                    "description": "ë“œë¥´ì¿°ë‹¤inì„±ì‚°ì—ì„œ ë””ì €íŠ¸ì™€ í•¨ê»˜ íœ´ì‹.",
                },
                {
                    "time_label": "ì €ë…",
                    "title": "ìš°ë„ ë“œë¼ì´ë¸Œ ë˜ëŠ” í•´ì•ˆë„ë¡œ ì‚°ì±…",
                    "spot_name": "ìš°ë„",
                    "description": "ë°° ì‹œê°„ì„ ë§ì¶° ìš°ë„ë¥¼ ë‹¤ë…€ì˜¤ê±°ë‚˜ ì„±ì‚° ì¼ëŒ€ í•´ì•ˆ ë“œë¼ì´ë¸Œ.",
                },
            ],
        }
    ],
    "west": [
        {
            "day": 1,
            "title": "1ì¼ì°¨: ê°ì„± ê°€ë“ ì„œìª½ ì½”ìŠ¤",
            "items": [
                {
                    "time_label": "ì˜¤ì „",
                    "title": "ë…¹ì°¨ë°­ê³¼ ì „ì‹œ ê´€ëŒ",
                    "spot_name": "ì˜¤ì„¤ë¡ í‹° ë®¤ì§€ì—„",
                    "description": "ì˜¤ì„¤ë¡ í‹° ë®¤ì§€ì—„ì—ì„œ ì œì£¼ ë…¹ì°¨ë°­ê³¼ ì „ì‹œ ê°ìƒ.",
                },
                {
                    "time_label": "ì ì‹¬",
                    "title": "ì„œìª½ ì§€ì—­ ì‹ë‹¹ì—ì„œ ì ì‹¬",
                    "spot_name": None,
                    "description": "í˜‘ì¬/í•œë¦¼ ì¼ëŒ€ì—ì„œ í•œì‹ ë˜ëŠ” í•´ì‚°ë¬¼ ì‹ì‚¬.",
                },
                {
                    "time_label": "ì˜¤í›„",
                    "title": "ì˜¤ë¦„ & ëª©ì¥ ì¹´í˜",
                    "spot_name": "ìƒˆë³„ì˜¤ë¦„",
                    "description": "ìƒˆë³„ì˜¤ë¦„ì—ì„œ ê°€ë²¼ìš´ íŠ¸ë ˆí‚¹ í›„ ëª©ì¥ì¹´í˜ ë“œë¥´ì¿°ë‹¤ì—ì„œ íœ´ì‹.",
                },
                {
                    "time_label": "ì˜¤í›„",
                    "title": "í…Œë§ˆíŒŒí¬ ì·¨í–¥ ì €ê²©",
                    "spot_name": "ìŠ¤ëˆ„í”¼ê°€ë“ ",
                    "description": "ìŠ¤ëˆ„í”¼ê°€ë“  ë˜ëŠ” ì‹ í™”í…Œë§ˆíŒŒí¬ ì¤‘ ì·¨í–¥ì— ë§ê²Œ ì„ íƒ ë°©ë¬¸.",
                },
                {
                    "time_label": "ì €ë…",
                    "title": "ì„œìª½ ë°”ë‹¤ ì„ ì…‹ ì¦ê¸°ê¸°",
                    "spot_name": "ê³½ì§€í•´ìˆ˜ìš•ì¥",
                    "description": "ê³½ì§€í•´ìˆ˜ìš•ì¥Â·ê¸ˆëŠ¥í•´ìˆ˜ìš•ì¥ì—ì„œ ë…¸ì„ ê°ìƒ í›„ ì¹´í˜ ë˜ëŠ” ìˆ™ì†Œë¡œ ì´ë™.",
                },
            ],
        }
    ],
    "south": [
        {
            "day": 1,
            "title": "1ì¼ì°¨: ì¤‘ë¬¸Â·ì„œê·€í¬ ë‚¨ìª½ ì½”ìŠ¤",
            "items": [
                {
                    "time_label": "ì˜¤ì „",
                    "title": "ì œì£¼ ë‚¨ìª½ ë°”ë‹¤ í’ê²½",
                    "spot_name": "ì‚°ë°©ì‚°",
                    "description": "ì‚°ë°©ì‚°ê³¼ ìš©ë¨¸ë¦¬í•´ì•ˆ ì¼ëŒ€ë¥¼ í•¨ê»˜ ë‘˜ëŸ¬ë³´ë©° í•´ì•ˆ ì ˆê²½ ê°ìƒ.",
                },
                {
                    "time_label": "ì ì‹¬",
                    "title": "ì¤‘ë¬¸Â·ì„œê·€í¬ ì‹ë‹¹ì—ì„œ ì ì‹¬",
                    "spot_name": None,
                    "description": "í•´ì‚°ë¬¼ ë˜ëŠ” í‘ë¼ì§€ ë“±ìœ¼ë¡œ ë“ ë“ í•˜ê²Œ ì ì‹¬.",
                },
                {
                    "time_label": "ì˜¤í›„",
                    "title": "í­í¬ & ê°•ê°€ ì‚°ì±…",
                    "spot_name": "ì²œì§€ì—°í­í¬",
                    "description": "ì²œì§€ì—°í­í¬ì™€ ì‡ ì†Œê¹ì„ ë°©ë¬¸í•´ ë‚¨ìª½ì˜ ë¬¼ê°€ í’ê²½ ì¦ê¸°ê¸°.",
                },
                {
                    "time_label": "ì €ë…",
                    "title": "ë§ˆë¼ë„ ë˜ëŠ” ì„œê·€í¬ ì‹œë‚´",
                    "spot_name": "ë§ˆë¼ë„",
                    "description": "ë°° ì‹œê°„ì„ ë§ì¶° ë§ˆë¼ë„ë¥¼ ë‹¤ë…€ì˜¤ê±°ë‚˜ ì„œê·€í¬ ì‹œë‚´ ì‚°ì±….",
                },
            ],
        }
    ],
    "north": [
        {
            "day": 1,
            "title": "1ì¼ì°¨: ì œì£¼ì‹œÂ·êµ¬ì¢Œ ë¶ìª½ ì½”ìŠ¤",
            "items": [
                {
                    "time_label": "ì˜¤ì „",
                    "title": "ê³µí•­ ê·¼ì²˜ í•´ì•ˆ ë“œë¼ì´ë¸Œ",
                    "spot_name": "ë„ë‘ë™ ë¬´ì§€ê°œ í•´ì•ˆë„ë¡œ",
                    "description": "ë„ë‘ë™ ë¬´ì§€ê°œ í•´ì•ˆë„ë¡œë¥¼ ë”°ë¼ ê°€ë³ê²Œ ì‚°ì±…í•˜ë©° ë°”ë‹¤ ë·° ê°ìƒ.",
                },
                {
                    "time_label": "ì ì‹¬",
                    "title": "ì œì£¼ì‹œë‚´ ì‹ì‚¬",
                    "spot_name": None,
                    "description": "ì œì£¼ì‹œ ë‚´ ì‹ë‹¹ì—ì„œ í•œì‹/ë¶„ì‹ ë“± ê°„ë‹¨íˆ ì ì‹¬.",
                },
                {
                    "time_label": "ì˜¤í›„",
                    "title": "ë°•ë¬¼ê´€ & ë°”ë‹¤",
                    "spot_name": "ë„¥ìŠ¨ì»´í“¨í„°ë°•ë¬¼ê´€",
                    "description": "ë„¥ìŠ¨ì»´í“¨í„°ë°•ë¬¼ê´€ ê´€ëŒ í›„, ì‚¼ì–‘í•´ìˆ˜ìš•ì¥Â·ê¹€ë…•í•´ìˆ˜ìš•ì¥ ë°©ë¬¸.",
                },
                {
                    "time_label": "ì €ë…",
                    "title": "ì‹œë‚´ ì•¼ê²½ & ì•¼ì‹œì¥",
                    "spot_name": "ë™ë¬¸ì¬ë˜ì‹œì¥",
                    "description": "ê´€ë•ì • ê·¼ì²˜ ì‚°ì±… í›„ ë™ë¬¸ì¬ë˜ì‹œì¥ì—ì„œ ì•¼ì‹œì¥ ë¨¹ê±°ë¦¬ ì¦ê¸°ê¸°.",
                },
            ],
        }
    ],
}

COURSE_KO_NAME_RB: Dict[str, str] = {
    "east": "ì œì£¼ ë™ìª½ ì½”ìŠ¤",
    "west": "ì œì£¼ ì„œìª½ ì½”ìŠ¤",
    "south": "ì œì£¼ ë‚¨ìª½ ì½”ìŠ¤",
    "north": "ì œì£¼ ë¶ìª½ ì½”ìŠ¤",
}


def _format_course_days_rb(days: List[CourseDayRB]) -> str:
    lines: List[str] = []
    for day in days:
        lines.append(f"ğŸ“… {day['title']}")
        for item in day["items"]:
            spot_part = f" ({item['spot_name']})" if item.get("spot_name") else ""
            lines.append(f" - {item['time_label']}: {item['title']}{spot_part}")
            if item.get("description"):
                lines.append(f"   Â· {item['description']}")
        lines.append("")
    return "\n".join(lines).strip()


def _build_single_course_answer(course_key: str) -> Optional[str]:
    if course_key not in COURSE_ITINERARY_RB:
        return None
    title = COURSE_KO_NAME_RB.get(course_key, "")
    body = _format_course_days_rb(COURSE_ITINERARY_RB[course_key])
    return f"ğŸ—º {title} ì¶”ì²œ ì¼ì •ì´ì—ìš”.\n\n{body}"


def _build_2n3d_answer() -> str:
    """
    2ë°• 3ì¼ ê¸°ë³¸ ë£¨íŠ¸ ì˜ˆì‹œ:
    1ì¼ì°¨ ì„œìª½ â†’ 2ì¼ì°¨ ë‚¨ìª½ â†’ 3ì¼ì°¨ ë™ìª½
    """
    order = ["west", "south", "east"]
    lines: List[str] = []
    lines.append("â›± 2ë°• 3ì¼ ì œì£¼ë„ ì¶”ì²œ ì½”ìŠ¤ì˜ˆìš”.")
    lines.append("ì˜ˆì‹œ ë£¨íŠ¸: 1ì¼ì°¨ ì„œìª½ â†’ 2ì¼ì°¨ ë‚¨ìª½ â†’ 3ì¼ì°¨ ë™ìª½\n")

    day_num = 1
    for key in order:
        days = COURSE_ITINERARY_RB.get(key)
        if not days:
            continue
        d = days[0]
        lines.append(f"ğŸ“… {day_num}ì¼ì°¨: {COURSE_KO_NAME_RB.get(key, d['title'])}")
        for item in d["items"]:
            spot_part = f" ({item['spot_name']})" if item.get("spot_name") else ""
            lines.append(f" - {item['time_label']}: {item['title']}{spot_part}")
        lines.append("")
        day_num += 1

    lines.append("ì›í•˜ë©´ ì´ ì½”ìŠ¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìˆ™ì†ŒÂ·ì‹ë‹¹ê¹Œì§€ ê°™ì´ ì¶”ì²œí•´ ì¤„ê²Œìš”.")
    return "\n".join(lines).strip()


def rule_based_course_answer(user_message: str) -> Optional[str]:
    """
    - 'ì œì£¼ ì„œìª½ ì½”ìŠ¤', 'ì œì£¼ì„œìª½ì½”ìŠ¤', 'ì„œìª½ ì¼ì • ì¶”ì²œ' ë“±
    - '2ë°•3ì¼ ì œì£¼ë„ ì½”ìŠ¤', 'ì œì£¼ 2ë°• 3ì¼ ì½”ìŠ¤' ë“±
    ì„ ê°ì§€í•´ì„œ ì½”ìŠ¤ í…ìŠ¤íŠ¸ë¥¼ ë°”ë¡œ ë°˜í™˜.
    """
    if not user_message:
        return None

    msg_no_space = user_message.replace(" ", "")
    # ì†Œë¬¸ì ë³€í™˜(ì˜ì–´ ëŒ€ë¹„ìš©)
    msg_no_space = msg_no_space.lower()

    # 2ë°• 3ì¼ íŒ¨í„´
    if (
        ("2ë°•3ì¼" in msg_no_space or ("2ë°•" in msg_no_space and "3ì¼" in msg_no_space))
        and "ì½”ìŠ¤" in msg_no_space
    ):
        return _build_2n3d_answer()

    # ë°©í–¥ë³„ ì½”ìŠ¤
    if "ì„œìª½" in msg_no_space and ("ì½”ìŠ¤" in msg_no_space or "ì¼ì •" in msg_no_space):
        return _build_single_course_answer("west")
    if "ë™ìª½" in msg_no_space and ("ì½”ìŠ¤" in msg_no_space or "ì¼ì •" in msg_no_space):
        return _build_single_course_answer("east")
    if "ë‚¨ìª½" in msg_no_space and ("ì½”ìŠ¤" in msg_no_space or "ì¼ì •" in msg_no_space):
        return _build_single_course_answer("south")
    if "ë¶ìª½" in msg_no_space and ("ì½”ìŠ¤" in msg_no_space or "ì¼ì •" in msg_no_space):
        return _build_single_course_answer("north")

    return None


# ------------------------------------------------
# 5. place / food / stay ì¹´í…Œê³ ë¦¬ ìë™ ë¶„ë¥˜
# ------------------------------------------------

def classify_category(row: pd.Series) -> str:
    t = str(row.get("type", "")).lower()
    kw = str(row.get("keywords", ""))
    desc = str(row.get("description", ""))

    text = t + " " + kw + " " + desc

    if any(word in text for word in [
        "í˜¸í…”", "ë¦¬ì¡°íŠ¸", "íœì…˜", "ê²ŒìŠ¤íŠ¸í•˜ìš°ìŠ¤", "ìˆ™ì†Œ", "ìˆ™ë°•",
        "hotel", "resort", "guesthouse", "stay"
    ]):
        return "stay"

    if any(word in text for word in [
        "ì‹ë‹¹", "ì¹´í˜", "ì»¤í”¼", "ë§›ì§‘", "ìŒì‹ì ",
        "restaurant", "cafe",
        "í‘ë¼ì§€", "ê³ ê¸°êµ­ìˆ˜", "í•´ì¥êµ­", "í•´ì‚°ë¬¼"
    ]):
        return "food"

    if "food" in t:
        return "food"
    if "stay" in t or "hotel" in t:
        return "stay"

    return "place"


df["category"] = df.apply(classify_category, axis=1)


# ------------------------------------------------
# 6. TF-IDF í•™ìŠµ (ì„œë²„ ì‹œì‘ ì‹œ 1ë²ˆ)
# ------------------------------------------------

vectorizer = TfidfVectorizer(token_pattern=r"(?u)\b\w+\b")
tfidf_matrix = vectorizer.fit_transform(df["search_text"])

df["stay_hours"] = df["category"].map(
    lambda c: 12.0 if c == "stay" else (1.0 if c == "food" else 1.5)
)


# ------------------------------------------------
# 7. í—¬í¼ í•¨ìˆ˜ë“¤ (ì •ë ¬, í›„ë³´ ì„ íƒ)
# ------------------------------------------------

def sort_by_subregion_then_similarity(sub_df: pd.DataFrame) -> pd.DataFrame:
    sub_df = sub_df.copy()
    sub_df["subregion"] = sub_df["subregion"].fillna("ê¸°íƒ€")
    order_map = {"ì œì£¼ ë™": 0, "ì œì£¼ ì„œ": 1, "ì„œê·€í¬ ë™": 2, "ì„œê·€í¬ ì„œ": 3, "ê¸°íƒ€": 4}
    sub_df["subrank"] = sub_df["subregion"].map(lambda x: order_map.get(x, 99))
    sub_df = sub_df.sort_values(
        by=["subrank", "similarity"],
        ascending=[True, False]
    ).reset_index(drop=True)
    return sub_df.drop(columns=["subrank"])


def get_best_candidate(
    df_cat: pd.DataFrame,
    used_indices: set,
    preferred_subregion: Optional[str] = None
) -> Optional[pd.Series]:
    if df_cat.empty:
        return None

    if preferred_subregion:
        sub = df_cat[
            (df_cat["subregion"] == preferred_subregion) &
            (~df_cat["orig_idx"].isin(used_indices))
        ]
        if not sub.empty:
            return sub.iloc[0]

    rest = df_cat[~df_cat["orig_idx"].isin(used_indices)]
    if rest.empty:
        return None
    return rest.iloc[0]


# ------------------------------------------------
# 8. ë©”ì¸ ì¶”ì²œ ë¡œì§ (mixed ë²„ì „)
# ------------------------------------------------

def recommend_itinerary_mixed(
    selected_tags: List[str],
    region_filter: Optional[str] = None,
    days: int = 1,
    max_places_per_day: int = 3,
    start_time_str: str = "09:00",
    daily_hours: float = 10.0,
    free_text: str = "",
) -> pd.DataFrame:
    """
    1) íƒœê·¸ + freeTextë¡œ ì „ì²´ ì¥ì†Œì— similarity ë¶€ì—¬
    2) place / food / stay ê°ê° ë­í‚¹
    3) placeë¡œ Dayë³„ ë¼ˆëŒ€ (Nì¼ Ã— Mê°œ) ë§Œë“¤ê¸°
    4) ê° Dayë§ˆë‹¤:
       - ê´€ê´‘ì§€ ì‚¬ì´ì— ê°™ì€ ì‚¬ë¶„ë©´ food 1ê°œ ë¼ì›Œ ë„£ê¸°
       - ë§ˆì§€ë§‰ì— ê°™ì€ ì‚¬ë¶„ë©´ stay 1ê°œ ë¶™ì´ê¸°
    5) ì¶œë°œ ì‹œê°„ë¶€í„° ì‹œê°„ ìˆœì„œë¡œ íƒ€ì„ë¼ì¸ ê³„ì‚°
    """

    query_text, merged_tags = build_query_from_tags(selected_tags, free_text=free_text)
    if not query_text.strip():
        return pd.DataFrame()

    candidate_df = df.copy()
    candidate_df["orig_idx"] = candidate_df.index

    # ì§€ì—­ í•„í„°
    if region_filter and region_filter.strip():
        mask_region = candidate_df["address"].str.contains(region_filter.strip(), na=False)
        candidate_df = candidate_df[mask_region]
        if len(candidate_df) == 0:
            candidate_df = df.copy()
            candidate_df["orig_idx"] = candidate_df.index

    # similarity ê³„ì‚°
    idx_list = candidate_df["orig_idx"].tolist()
    candidate_tfidf = tfidf_matrix[idx_list]
    query_vec = vectorizer.transform([query_text])
    cosine_sim = linear_kernel(query_vec, candidate_tfidf).flatten()
    candidate_df["similarity"] = cosine_sim

    place_df = sort_by_subregion_then_similarity(
        candidate_df[candidate_df["category"] == "place"]
    ).copy()
    food_df = sort_by_subregion_then_similarity(
        candidate_df[candidate_df["category"] == "food"]
    ).copy()
    stay_df = sort_by_subregion_then_similarity(
        candidate_df[candidate_df["category"] == "stay"]
    ).copy()

    if place_df.empty and food_df.empty and stay_df.empty:
        return pd.DataFrame()

    total_place_needed = days * max_places_per_day
    place_df = place_df.head(total_place_needed).reset_index(drop=True)

    try:
        base_time = datetime.strptime(start_time_str, "%H:%M")
    except Exception:
        base_time = datetime.strptime("09:00", "%H:%M")

    used_indices: set = set()
    results = []

    for day in range(1, days + 1):
        start_idx = (day - 1) * max_places_per_day
        end_idx = day * max_places_per_day
        day_places = place_df.iloc[start_idx:end_idx]
        day_places = day_places[~day_places["orig_idx"].isin(used_indices)].reset_index(drop=True)

        if day_places.empty:
            continue

        day_start_time = base_time
        current_time = base_time
        day_end_limit = base_time + timedelta(hours=daily_hours)

        prev_subregion = None
        order_in_day = 0

        dominant_sub = (
            day_places["subregion"].value_counts().idxmax()
            if not day_places["subregion"].empty
            else None
        )

        day_food_candidate = get_best_candidate(
            food_df, used_indices, preferred_subregion=dominant_sub
        )
        food_insert_after = 1
        food_inserted = False

        for i, (_, place_row) in enumerate(day_places.iterrows()):
            place_sub = place_row["subregion"]
            stay_h = float(place_row["stay_hours"])

            travel_h = 0.5 if order_in_day == 0 else get_travel_time(prev_subregion, place_sub)

            arrival_time = current_time + timedelta(hours=travel_h)
            end_time = arrival_time + timedelta(hours=stay_h)

            if end_time > day_end_limit + timedelta(hours=1):
                continue

            order_in_day += 1
            used_indices.add(place_row["orig_idx"])

            results.append({
                "day": day,
                "order_in_day": order_in_day,
                "name": place_row.get("name", ""),
                "category": "place",
                "address": place_row.get("address", ""),
                "region_city": place_row.get("region_city", ""),
                "subregion": place_sub,
                "keywords": place_row.get("keywords", ""),
                "description": place_row.get("description", ""),
                "similarity": float(place_row.get("similarity", 0.0)),
                "lat": place_row.get("lat"),
                "lng": place_row.get("lng"),
                "visit_start": arrival_time.strftime("%H:%M"),
                "visit_end": end_time.strftime("%H:%M"),
                "travel_hours": travel_h,
                "stay_hours": stay_h,
            })

            current_time = end_time
            prev_subregion = place_sub

            # ìŒì‹ ë¼ì›Œë„£ê¸°
            if (not food_inserted) and day_food_candidate is not None and (i + 1 == food_insert_after):
                food_sub = day_food_candidate["subregion"]
                food_stay_h = float(day_food_candidate["stay_hours"])
                travel_h_food = get_travel_time(prev_subregion, food_sub)

                arrive_food = current_time + timedelta(hours=travel_h_food)
                end_food = arrive_food + timedelta(hours=food_stay_h)

                if end_food <= day_end_limit + timedelta(hours=1):
                    order_in_day += 1
                    used_indices.add(day_food_candidate["orig_idx"])

                    results.append({
                        "day": day,
                        "order_in_day": order_in_day,
                        "name": day_food_candidate.get("name", ""),
                        "category": "food",
                        "address": day_food_candidate.get("address", ""),
                        "region_city": day_food_candidate.get("region_city", ""),
                        "subregion": food_sub,
                        "keywords": day_food_candidate.get("keywords", ""),
                        "description": day_food_candidate.get("description", ""),
                        "similarity": float(day_food_candidate.get("similarity", 0.0)),
                        "lat": day_food_candidate.get("lat"),
                        "lng": day_food_candidate.get("lng"),
                        "visit_start": arrive_food.strftime("%H:%M"),
                        "visit_end": end_food.strftime("%H:%M"),
                        "travel_hours": travel_h_food,
                        "stay_hours": food_stay_h,
                    })

                    current_time = end_food
                    prev_subregion = food_sub
                    food_inserted = True

        # ìˆ™ì†Œ
        if prev_subregion is not None:
            day_stay_candidate = get_best_candidate(
                stay_df, used_indices, preferred_subregion=prev_subregion
            )
        else:
            day_stay_candidate = get_best_candidate(
                stay_df, used_indices, preferred_subregion=None
            )

        if day_stay_candidate is not None and prev_subregion is not None:
            stay_sub = day_stay_candidate["subregion"]
            stay_h = float(day_stay_candidate["stay_hours"])
            travel_h_stay = get_travel_time(prev_subregion, stay_sub)

            arrive_stay = current_time + timedelta(hours=travel_h_stay)
            end_stay = arrive_stay + timedelta(hours=stay_h)

            if end_stay <= day_end_limit + timedelta(hours=2):
                order_in_day += 1
                used_indices.add(day_stay_candidate["orig_idx"])

                results.append({
                    "day": day,
                    "order_in_day": order_in_day,
                    "name": day_stay_candidate.get("name", ""),
                    "category": "stay",
                    "address": day_stay_candidate.get("address", ""),
                    "region_city": day_stay_candidate.get("region_city", ""),
                    "subregion": stay_sub,
                    "keywords": day_stay_candidate.get("keywords", ""),
                    "description": day_stay_candidate.get("description", ""),
                    "similarity": float(day_stay_candidate.get("similarity", 0.0)),
                    "lat": day_stay_candidate.get("lat"),
                    "lng": day_stay_candidate.get("lng"),
                    "visit_start": arrive_stay.strftime("%H:%M"),
                    "visit_end": end_stay.strftime("%H:%M"),
                    "travel_hours": travel_h_stay,
                    "stay_hours": stay_h,
                })

    if not results:
        return pd.DataFrame()

    return pd.DataFrame(results)


# ------------------------------------------------
# 9. API Request / Response ëª¨ë¸ ì •ì˜
# ------------------------------------------------

class RecommendRequest(BaseModel):
    tags: List[str] = []              # ["ìì—°", "ì‚¬ì§„", ...] (í”„ë¡ íŠ¸ TAGS ê¸°ì¤€)
    region: Optional[str] = None      # "ì œì£¼ì‹œ", "ì„œê·€í¬ì‹œ" ë“± (ì—†ìœ¼ë©´ None)
    days: int = 1                     # ì—¬í–‰ ì¼ìˆ˜
    max_places_per_day: int = 3       # í•˜ë£¨ ê´€ê´‘ì§€ ê°œìˆ˜
    daily_hours: float = 10.0         # í•˜ë£¨ ìµœëŒ€ ì—¬í–‰ ì‹œê°„
    start_time: str = "09:00"         # "HH:MM"
    freeText: Optional[str] = ""      # ì¶”ê°€ í‚¤ì›Œë“œ (ì˜ˆ: "ì˜¤ë¦„, ì¹´í˜, ë“œë¼ì´ë¸Œ")


class ItineraryItem(BaseModel):
    day: int
    order_in_day: int
    name: str
    category: str            # "place" / "food" / "stay"
    address: str
    region_city: str
    subregion: str
    keywords: str
    description: str
    similarity: float
    lat: Optional[float]
    lng: Optional[float]
    visit_start: str         # "HH:MM"
    visit_end: str           # "HH:MM"
    travel_hours: float
    stay_hours: float


class DayPlan(BaseModel):
    day: int
    total_travel_hours: float
    total_stay_hours: float
    start_time: str
    end_time: str
    items: List[ItineraryItem]


class RecommendResponse(BaseModel):
    days: List[DayPlan]


def itinerary_df_to_response(itinerary_df: pd.DataFrame) -> RecommendResponse:
    """DataFrame -> RecommendResponse ë³€í™˜ ê³µí†µ í•¨ìˆ˜"""
    if itinerary_df.empty:
        return RecommendResponse(days=[])

    days_result: List[DayPlan] = []

    for day in sorted(itinerary_df["day"].unique()):
        day_df = itinerary_df[itinerary_df["day"] == day].copy()
        day_df = day_df.sort_values("order_in_day")

        total_travel = float(day_df["travel_hours"].sum())
        total_stay = float(day_df["stay_hours"].sum())
        start_time = str(day_df["visit_start"].iloc[0])
        end_time = str(day_df["visit_end"].iloc[-1])

        items: List[ItineraryItem] = []
        for _, row in day_df.iterrows():
            item = ItineraryItem(
                day=int(row["day"]),
                order_in_day=int(row["order_in_day"]),
                name=str(row["name"]),
                category=str(row["category"]),
                address=str(row["address"]),
                region_city=str(row["region_city"]),
                subregion=str(row["subregion"]),
                keywords=str(row["keywords"]),
                description=str(row["description"]),
                similarity=float(row["similarity"]),
                lat=float(row["lat"]) if not pd.isna(row["lat"]) else None,
                lng=float(row["lng"]) if not pd.isna(row["lng"]) else None,
                visit_start=str(row["visit_start"]),
                visit_end=str(row["visit_end"]),
                travel_hours=float(row["travel_hours"]),
                stay_hours=float(row["stay_hours"]),
            )
            items.append(item)

        days_result.append(
            DayPlan(
                day=int(day),
                total_travel_hours=total_travel,
                total_stay_hours=total_stay,
                start_time=start_time,
                end_time=end_time,
                items=items,
            )
        )

    return RecommendResponse(days=days_result)


# ------------------------------------------------
# 10. /recommend ì—”ë“œí¬ì¸íŠ¸
# ------------------------------------------------

@app.post("/recommend", response_model=RecommendResponse)
def recommend(req: RecommendRequest):
    itinerary_df = recommend_itinerary_mixed(
        selected_tags=req.tags,
        region_filter=req.region,
        days=req.days,
        max_places_per_day=req.max_places_per_day,
        start_time_str=req.start_time,
        daily_hours=req.daily_hours,
        free_text=req.freeText or "",
    )

    return itinerary_df_to_response(itinerary_df)


# ------------------------------------------------
# 11. ì±—ë´‡ìš© /chat ì—”ë“œí¬ì¸íŠ¸
# ------------------------------------------------

class ChatRequest(BaseModel):
    message: str


class ChatResponse(BaseModel):
    reply: str
    itinerary: RecommendResponse


@app.post("/chat", response_model=ChatResponse)
def chat(req: ChatRequest):
    """
    1) ë¨¼ì € rule_based_course_answerë¡œ ë™/ì„œ/ë‚¨/ë¶/2ë°•3ì¼ ì½”ìŠ¤ì¸ì§€ í™•ì¸
       - í•´ë‹¹ë˜ë©´ ê·¸ ì½”ìŠ¤ í…ìŠ¤íŠ¸ë¥¼ replyë¡œ ë°˜í™˜, itineraryëŠ” ë¹ˆ ê°’
    2) ì•„ë‹ˆë©´ parse_chat_messageë¡œ í•´ì„í•´ì„œ recommend_itinerary_mixed ì‚¬ìš©
    """
    # 1) ë™/ì„œ/ë‚¨/ë¶/2ë°•3ì¼ ì½”ìŠ¤ ë£° ê¸°ë°˜ ì‘ë‹µ
    rb_answer = rule_based_course_answer(req.message)
    if rb_answer:
        empty_resp = RecommendResponse(days=[])
        return ChatResponse(reply=rb_answer, itinerary=empty_resp)

    # 2) ì¼ë°˜ ì±—ë´‡ ì½”ìŠ¤ ì¶”ì²œ ë¡œì§
    ctx = parse_chat_message(req.message)

    itinerary_df = recommend_itinerary_mixed(
        selected_tags=ctx["tags"],
        region_filter=ctx["region_filter"],
        days=ctx["days"],
        max_places_per_day=ctx["max_places_per_day"],
        start_time_str=ctx["start_time_str"],
        daily_hours=10.0,
        free_text=req.message,
    )

    resp = itinerary_df_to_response(itinerary_df)
    reply_text = summarize_itinerary_for_chat(resp, ctx, req.message)

    return ChatResponse(
        reply=reply_text,
        itinerary=resp,
    )



def summarize_itinerary_for_chat(resp: RecommendResponse, ctx: dict, original_message: str) -> str:
    """
    ì¶”ì²œ ê²°ê³¼ + íŒŒì‹±ëœ ì¡°ê±´(ctx)ì„ ë°”íƒ•ìœ¼ë¡œ
    ì‚¬ëŒì´ ì½ê¸° ì¢‹ì€ í•œê¸€ ì„¤ëª…ì„ ë§Œë“ ë‹¤.
    """
    if not resp.days:
        return "ì¡°ê±´ì— ë§ëŠ” ì½”ìŠ¤ë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš”. ë‚ ì§œ/ì§€ì—­/ì›í•˜ëŠ” ë¶„ìœ„ê¸°ë¥¼ ì¡°ê¸ˆ ë” ìì„¸íˆ ì•Œë ¤ì¤„ë˜ìš”?"

    desc_parts = []

    # 1) ì‚¬ìš©ìê°€ ë³´ë‚¸ ë¬¸ì¥
    if original_message:
        desc_parts.append(f"ìš”ì²­í•˜ì‹  \"{original_message}\" ì¡°ê±´ì„ ë°”íƒ•ìœ¼ë¡œ ì½”ìŠ¤ë¥¼ ë§Œë“¤ì–´ ë´¤ì–´ìš” ğŸ˜Š")

    # 2) íŒŒì‹±ëœ ì¡°ê±´ ê°„ë‹¨ ìš”ì•½
    cond_parts = []
    days = ctx.get("days")
    if days:
        cond_parts.append(f"{days}ì¼ ì¼ì •")

    region_label = ctx.get("region_label")
    if region_label:
        cond_parts.append(region_label)

    tags = ctx.get("tags") or []
    if tags:
        # ë„ˆë¬´ ë§ìœ¼ë©´ 2~3ê°œë§Œ
        show_tags = tags[:3]
        cond_parts.append(" / ".join(show_tags) + " ë¶„ìœ„ê¸°")

    if cond_parts:
        desc_parts.append(" Â· ".join(cond_parts))

    lines: List[str] = []

    # 3) ì¼ìë³„ ì½”ìŠ¤ ìš”ì•½
    for day_plan in resp.days:
        items_text = " â†’ ".join(
            f"{item.name}({item.category}, {item.visit_start}~{item.visit_end})"
            for item in day_plan.items
        )
        lines.append(
            f"{day_plan.day}ì¼ì°¨ ({day_plan.start_time}~{day_plan.end_time}) : {items_text}"
        )

    desc_parts.extend(lines)
    desc_parts.append("ì„¸ë¶€ ì¼ì •ì€ í™”ë©´ì—ì„œ íƒ€ì„ë¼ì¸ìœ¼ë¡œë„ í™•ì¸í•  ìˆ˜ ìˆì–´ìš”!")

    return "\n".join(desc_parts)



# ------------------------------------------------
# 12. ë¡œì»¬ ì‹¤í–‰ ë°©ë²• (í„°ë¯¸ë„ì—ì„œ)
# ------------------------------------------------
# uvicorn main:app --reload --port 8000
#
# ì˜ˆ: http://127.0.0.1:8000/docs ì—ì„œ ìŠ¤ì›¨ê±° UIë¡œ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥
